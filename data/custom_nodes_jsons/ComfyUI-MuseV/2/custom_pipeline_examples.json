[
    {
        "question": "ComfyUI-MuseV는 어떤 기능을 제공하나요?",
        "answer": "ComfyUI-MuseV는 CLIP 가이드 기반의 Stable Diffusion, One Step U-Net, Stable Diffusion Interpolation, Stable Diffusion Mega, Long Prompt Weighting Stable Diffusion, Speech to Image 등의 기능을 제공합니다."
    },
    {
        "question": "CLIP 가이드 기반의 Stable Diffusion은 어떤 장점이 있나요?",
        "answer": "CLIP 가이드 기반의 Stable Diffusion은 모든 노이즈 제거 단계에서 추가 CLIP 모델을 통해 Stable Diffusion을 가이드함으로써 보다 더 사실적인 이미지를 생성할 수 있습니다."
    },
    {
        "question": "Stable Diffusion Interpolation은 어떻게 작동하나요?",
        "answer": "Stable Diffusion Interpolation은 서로 다른 프롬프트/시드 간 Stable Diffusion의 latent space 보간을 수행합니다. 약 8GB VRAM의 GPU에서 실행할 수 있으며 약 5분 정도 소요됩니다."
    },
    {
        "question": "Stable Diffusion Mega 파이프라인의 특징은 무엇인가요?",
        "answer": "Stable Diffusion Mega 파이프라인을 사용하면 Stable Diffusion 파이프라인의 주요 사용 사례를 단일 클래스에서 사용할 수 있습니다. 텍스트-이미지 변환, 이미지-이미지 변환, 인페인팅 등을 모두 실행할 수 있습니다."
    },
    {
        "question": "Long Prompt Weighting Stable Diffusion의 장점은 무엇인가요?",
        "answer": "Long Prompt Weighting Stable Diffusion 파이프라인을 사용하면 토큰 길이 제한 없이 프롬프트를 입력할 수 있고, '()'나 '[]'를 사용하여 단어 가중치를 조절할 수 있습니다. 또한 Stable Diffusion 파이프라인의 주요 사용 사례를 단일 클래스에서 사용할 수 있습니다."
    },
    {
        "question": "Speech to Image 기능은 어떤原理로 작동하나요?",
        "answer": "Speech to Image 기능은 사전학습된 OpenAI whisper-small과 Stable Diffusion을 사용하여 오디오 샘플에서 텍스트를 작성하고 해당 텍스트를 기반으로 이미지를 생성합니다."
    },
    {
        "question": "ComfyUI-MuseV의 커뮤니티 파이프라인은 어떻게 사용할 수 있나요?",
        "answer": "커스텀 파이프라인을 불러오려면 `diffusers/examples/community`에 있는 파일 중 하나로서 `custom_pipeline` 인수를 `DiffusionPipeline`에 전달하기만 하면 됩니다."
    }
]