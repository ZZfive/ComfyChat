[
    {
        "question": "What is DiT?",
        "answer": "DiT stands for Diffusion Transformers, a new class of diffusion models based on the transformer architecture."
    },
    {
        "question": "Who are the authors of the DiT paper?",
        "answer": "The authors of the DiT paper are William Peebles and Saining Xie."
    },
    {
        "question": "What is the main idea behind DiT models?",
        "answer": "DiT models replace the commonly-used U-Net backbone with a transformer that operates on latent patches."
    },
    {
        "question": "What is the scalability of DiT models measured by?",
        "answer": "The scalability of DiT models is measured by the forward pass complexity, as measured by Gflops."
    },
    {
        "question": "How do DiT models with higher Gflops perform?",
        "answer": "DiT models with higher Gflops, through increased transformer depth/width or increased number of input tokens, consistently have lower FID."
    },
    {
        "question": "What is the performance of DiT-XL/2 models on the class-conditional ImageNet 256x256 benchmark?",
        "answer": "The DiT-XL/2 models achieve a state-of-the-art FID of 2.27 on the class-conditional ImageNet 256x256 benchmark."
    },
    {
        "question": "Where can the original DiT codebase be found?",
        "answer": "The original DiT codebase can be found at facebookresearch/dit on GitHub."
    }
]