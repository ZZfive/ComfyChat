[
    {
        "question": "What is Shap-E?",
        "answer": "Shap-E is a conditional generative model for 3D assets that directly generates the parameters of implicit functions."
    },
    {
        "question": "What are the two stages of training Shap-E?",
        "answer": "The two stages of training Shap-E are: 1) training an encoder that deterministically maps 3D assets into the parameters of an implicit function, and 2) training a conditional diffusion model on outputs of the encoder."
    },
    {
        "question": "What is the difference between Shap-E and Point-E?",
        "answer": "Shap-E converges faster and reaches comparable or better sample quality compared to Point-E, despite modeling a higher-dimensional, multi-representation output space."
    },
    {
        "question": "What are the outputs of the Shap-E model?",
        "answer": "The outputs of the Shap-E model are textured meshes and neural radiance fields generated from the parameters of implicit functions."
    },
    {
        "question": "What is the purpose of the ShapEPipeline?",
        "answer": "The ShapEPipeline is used to generate 3D assets conditioned on text prompts using the Shap-E model."
    },
    {
        "question": "What is the purpose of the ShapEImg2ImgPipeline?",
        "answer": "The ShapEImg2ImgPipeline is used to generate 3D assets conditioned on an input image and text prompts using the Shap-E model."
    },
    {
        "question": "What does the ShapEPipelineOutput contain?",
        "answer": "The ShapEPipelineOutput contains the generated 3D assets, such as textured meshes and neural radiance fields, from the Shap-E model."
    }
]