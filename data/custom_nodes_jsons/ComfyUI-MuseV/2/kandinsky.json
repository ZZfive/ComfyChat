[
    {
        "question": "What is Kandinsky 2.1?",
        "answer": "Kandinsky 2.1 is a model that inherits best practices from Dall-E 2 and Latent diffusion while introducing new ideas. It uses a CLIP model and diffusion image prior (mapping) between latent spaces of CLIP modalities for text and image encoding."
    },
    {
        "question": "Who are the creators of Kandinsky 2.1?",
        "answer": "Kandinsky 2.1 is created by Arseniy Shakhmatov, Anton Razzhigaev, Aleksandr Nikolich, Vladimir Arkhipkin, Igor Pavlov, Andrey Kuznetsov, and Denis Dimitrov."
    },
    {
        "question": "Where can the original codebase of Kandinsky 2.1 be found?",
        "answer": "The original codebase of Kandinsky 2.1 can be found at ai-forever/Kandinsky-2 on GitHub."
    },
    {
        "question": "What are some of the official model checkpoints available for Kandinsky 2.1?",
        "answer": "The official model checkpoints for tasks like text-to-image, image-to-image, and inpainting can be found at the Kandinsky Community organization on the Hub."
    },
    {
        "question": "What are some of the pipelines available in Kandinsky 2.1?",
        "answer": "Some of the pipelines available in Kandinsky 2.1 include KandinskyPriorPipeline, KandinskyPipeline, KandinskyCombinedPipeline, KandinskyImg2ImgPipeline, KandinskyImg2ImgCombinedPipeline, KandinskyInpaintPipeline, and KandinskyInpaintCombinedPipeline."
    },
    {
        "question": "What is the purpose of the Schedulers guide in Kandinsky 2.1?",
        "answer": "The Schedulers guide in Kandinsky 2.1 helps users learn how to explore the tradeoff between scheduler speed and quality."
    },
    {
        "question": "What can be learned from the 'reuse components across pipelines' section in Kandinsky 2.1?",
        "answer": "The 'reuse components across pipelines' section in Kandinsky 2.1 teaches users how to efficiently load the same components into multiple pipelines."
    }
]