[
    {
        "messages": [
            {
                "role": "user",
                "content": "What is ComfyUI-YoloNasPose-Tensorrt?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI-YoloNasPose-Tensorrt is a ComfyUI Custom Node implementation of YOLO-NAS-POSE, powered by TensorRT for ultra fast pose estimation."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is the license for ComfyUI-YoloNasPose-Tensorrt?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI-YoloNasPose-Tensorrt is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is the performance of YOLO-NAS-POSE-L model with FP32 precision on an H100 device?"
            },
            {
                "role": "assistant",
                "content": "The YOLO-NAS-POSE-L model with FP32 precision achieves 105 FPS on an H100 device with a model input resolution of 640x640 and an image resolution of 1280x720."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "How can I install ComfyUI-YoloNasPose-Tensorrt?"
            },
            {
                "role": "assistant",
                "content": "To install ComfyUI-YoloNasPose-Tensorrt, navigate to the ComfyUI /custom_nodes directory, clone the repository, and install the required packages using pip install -r requirements.txt."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "How do I build the TensorRT engine for ComfyUI-YoloNasPose-Tensorrt?"
            },
            {
                "role": "assistant",
                "content": "To build the TensorRT engine, download an onnx model, edit the model paths in export_trt.py, run the script, and place the exported tensorrt engine inside the ComfyUI /models/tensorrt/yolo-nas-pose directory."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "How can I use ComfyUI-YoloNasPose-Tensorrt in ComfyUI?"
            },
            {
                "role": "assistant",
                "content": "To use ComfyUI-YoloNasPose-Tensorrt in ComfyUI, insert the node by Right Click -> tensorrt -> Yolo Nas Pose Tensorrt and choose the appropriate engine from the dropdown."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What environment has ComfyUI-YoloNasPose-Tensorrt been tested on?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI-YoloNasPose-Tensorrt has been tested on Ubuntu 22.04 LTS with Cuda 12.4, Tensorrt 10.1.0, Python 3.10, and an H100 GPU. It has not been tested on Windows but should work."
            }
        ]
    }
]