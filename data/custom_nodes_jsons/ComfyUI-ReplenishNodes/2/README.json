[
    {
        "question": "What does the CLIPSeg node do?",
        "answer": "The CLIPSeg node generates a binary mask for a given input image and text prompt."
    },
    {
        "question": "What are the inputs for the CLIPSeg node?",
        "answer": "The inputs for the CLIPSeg node are: - image: A torch.Tensor representing the input image. - text: A string representing the text prompt. - blur: A float value to control the amount of Gaussian blur applied to the mask. - threshold: A float value to control the threshold for creating the binary mask. - dilation_factor: A float value to control the dilation of the binary mask."
    },
    {
        "question": "What are the outputs for the CLIPSeg node?",
        "answer": "The outputs for the CLIPSeg node are: - tensor_bw: A torch.Tensor representing the binary mask. - image_out_hm: A torch.Tensor representing the heatmap overlay on the input image. - image_out_bw: A torch.Tensor representing the binary mask overlay on the input image."
    },
    {
        "question": "What does the CombineSegMasks node do?",
        "answer": "The CombineSegMasks node combines two or optionally three masks into a single mask to improve masking of different areas."
    },
    {
        "question": "What are the inputs for the CombineSegMasks node?",
        "answer": "The inputs for the CombineSegMasks node are: - image: A torch.Tensor representing the input image. - mask1: A torch.Tensor representing the first mask. - mask2: A torch.Tensor representing the second mask. - mask3 (optional): A torch.Tensor representing the third mask. Defaults to None."
    },
    {
        "question": "What are the outputs for the CombineSegMasks node?",
        "answer": "The outputs for the CombineSegMasks node are: - combined_mask: A torch.Tensor representing the combined mask. - image_out_hm: A torch.Tensor representing the heatmap overlay of the combined mask on the input image. - image_out_bw: A torch.Tensor representing the binary mask overlay of the combined mask on the input image."
    },
    {
        "question": "How can these custom nodes be installed?",
        "answer": "To use these custom nodes in a ComfyUI project, clone this repository or download the source code, put the clipseg.py file into the custom_nodes directory, and follow the-walkthrough-provided-in-the-repository."
    },
    {
        "question": "What are the requirements for using these nodes?",
        "answer": "The requirements are: - PyTorch - CLIPSeg - OpenCV - numpy - matplotlib"
    }
]