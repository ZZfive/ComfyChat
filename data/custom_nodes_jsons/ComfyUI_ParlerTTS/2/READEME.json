[
    {
        "question": "What does the Parler-TTS model architecture consist of?",
        "answer": "The Parler-TTS model architecture consists of three distinct stages: 1. Text encoder: maps text descriptions to hidden-state representations. 2. Parler-TTS decoder: a language model that auto-regressively generates audio tokens. 3. Audio codec: used to recover audio waveform from audio tokens."
    },
    {
        "question": "How is the Parler-TTS model trained?",
        "answer": "The Parler-TTS model is trained by loading the dataset, pre-computing audio tokens, and then training the model. The training includes loading multiple training datasets, metadatasets, configurations, and splits. After training, the model can be evaluated and generated audio samples can be stored."
    },
    {
        "question": "What are the prerequisites for training the Parler-TTS model?",
        "answer": "The prerequisites for training the Parler-TTS model include: 1. Installation of required libraries, such as PyTorch and Accelerate. 2. Finding or initializing the model to train, either a pre-trained model or a model from scratch. 3. Preparing the dataset, which includes speech data, text transcription of the speech data, and conditionning text description. 4. Configuring Accelerate to specify the number of GPUs and data type for training/inference."
    },
    {
        "question": "How can one initialize a model for training?",
        "answer": "One can initialize a model for training by using the `init_model_600M.py` script. This script allows for initializing a model from scratch, using the `google/flan-t5-base` text model and `parler-tts/dac_44khZ_8kbps` audio model."
    },
    {
        "question": "What does the Data-Speech library allow for?",
        "answer": "The Data-Speech library allows for annotating the speaker and utterance characteristics with natural language description. It is used to annotate the speech data used for training the Parler-TTS model."
    },
    {
        "question": "What is the purpose of the `accelerate config` command?",
        "answer": "The `accelerate config` command is used to configure Accelerate, which is a library from Hugging Face that provides a command-line interface for running distributed machine learning experiments. It allows for specifying the number of GPUs and data type for training/inference."
    },
    {
        "question": "What is the purpose of the `wandb` library?",
        "answer": "The `wandb` (Weights & Biases) library is used for better tracking of the experiments' metrics and losses. It allows for logging the training and evaluation metrics to the `wandb` platform."
    }
]