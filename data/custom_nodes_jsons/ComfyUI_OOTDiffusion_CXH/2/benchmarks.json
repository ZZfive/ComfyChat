[
    {
        "question": "What hardware was used for the Mask R-CNN benchmarks?",
        "answer": "The benchmarks used 8 NVIDIA V100s with NVLink."
    },
    {
        "question": "What software versions were used for the Mask R-CNN benchmarks?",
        "answer": "The benchmarks used Python 3.7, CUDA 10.1, cuDNN 7.6.5, PyTorch 1.5, TensorFlow 1.15.0rc2, Keras 2.2.5, MxNet 1.6.0b20190820."
    },
    {
        "question": "What model was used for the Mask R-CNN benchmarks?",
        "answer": "An end-to-end R-50-FPN Mask-RCNN model was used, with the same hyperparameters as the Detectron baseline config."
    },
    {
        "question": "How was the throughput metric calculated for the Mask R-CNN benchmarks?",
        "answer": "The average throughput in iterations 100-500 was used to skip GPU warmup time."
    },
    {
        "question": "Which implementation had the highest throughput in the Mask R-CNN benchmarks?",
        "answer": "Detectron2 with PyTorch had the highest throughput at 62 img/s."
    },
    {
        "question": "How does the throughput of R-CNN-style models typically change during training?",
        "answer": "The throughput of R-CNN-style models typically changes during training because it depends on the predictions of the model."
    },
    {
        "question": "Why is the throughput metric used in the benchmarks not directly comparable with 'train speed' in model zoo?",
        "answer": "The throughput metric is not directly comparable with 'train speed' in model zoo because 'train speed' is the average speed of the entire training run."
    }
]