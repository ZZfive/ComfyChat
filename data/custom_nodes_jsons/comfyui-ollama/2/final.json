[
    {
        "messages": [
            {
                "role": "user",
                "content": "What change was made to the OllamaAdvanced node on 31-08-2024?"
            },
            {
                "role": "assistant",
                "content": "On 31-08-2024, the change was made to merge the `top_k` and `num_predict` parameters in the OllamaAdvanced node to be INT instead of FLOAT."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What are the two new nodes added on 30-07-2024?"
            },
            {
                "role": "assistant",
                "content": "On 30-07-2024, two new nodes were added: OllamaSaveContext and OllamaLoadContext. OllamaSaveContext saves context from OllamaGenerateAdvance to a `png` file, while OllamaLoadContext loads context for OllamaGenerateAdvance from a `png` file."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What modification was made to the `context` input in the OllamaGenerateAdvance node?"
            },
            {
                "role": "assistant",
                "content": "The `context` input in the OllamaGenerateAdvance node was modified to handle string data type as well."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What option was added to the OllamaGenerateAdvance node on 18-06-2024?"
            },
            {
                "role": "assistant",
                "content": "On 18-06-2024, the `keep_context` option was added to the OllamaGenerateAdvance node, allowing the current run's context to be preserved within the node itself."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What modification was made to the debug flag on 18-06-2024?"
            },
            {
                "role": "assistant",
                "content": "On 18-06-2024, the debug flag was modified to be a boolean data type."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What feature was added on 24-05-2024 regarding ollama models?"
            },
            {
                "role": "assistant",
                "content": "On 24-05-2024, a drop-down list was added to select ollama models that are currently available in the ollama server."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is the purpose of the `keep_alive` option added on 23-05-2024?"
            },
            {
                "role": "assistant",
                "content": "The `keep_alive` option, added on 23-05-2024, controls how long the selected model will stay loaded into memory following a request, with a default value of 5 minutes."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What change was made to the Ollama Generate Advance node on 21-05-2024?"
            },
            {
                "role": "assistant",
                "content": "On 21-05-2024, the Ollama Generate Advance node was modified, changing the seed data type from 'FLOAT' to 'INT'."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is ComfyUI Ollama?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI Ollama is a set of custom nodes for ComfyUI that allow interaction with Ollama, a large language model, using the Ollama Python client."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is required to use ComfyUI Ollama properly?"
            },
            {
                "role": "assistant",
                "content": "To use ComfyUI Ollama properly, you need a running Ollama server that is reachable from the host running ComfyUI."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "How can you install ComfyUI Ollama?"
            },
            {
                "role": "assistant",
                "content": "You can install ComfyUI Ollama using the ComfyUI Manager 'Custom Node Manager' or by cloning the repository into the 'custom_nodes' folder of your ComfyUI installation and running 'pip install -r requirements.txt'."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What does the OllamaVision node do?"
            },
            {
                "role": "assistant",
                "content": "The OllamaVision node allows you to query input images using an Ollama model with vision abilities."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is the purpose of the OllamaGenerate node?"
            },
            {
                "role": "assistant",
                "content": "The OllamaGenerate node allows you to query an Ollama language model using a given prompt."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What additional features does the OllamaGenerateAdvance node provide?"
            },
            {
                "role": "assistant",
                "content": "The OllamaGenerateAdvance node allows you to query an Ollama language model using a given prompt with fine-tuned parameters and the ability to preserve context for generate chaining."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "Where can you find more information about the parameters used in the OllamaGenerateAdvance node?"
            },
            {
                "role": "assistant",
                "content": "You can find more information about the parameters used in the OllamaGenerateAdvance node in the Ollama API docs and the model file documentation."
            }
        ]
    }
]