[
    {
        "question": "What is the purpose of the AV_IPAdapter node in Art Venture framework?",
        "answer": "The AV_IPAdapter node is designed to integrate and apply IP Adapter models to images within the Art Venture framework. It facilitates image enhancement or alteration by utilizing IP Adapter and CLIP vision models, allowing customization of visual content based on specified parameters and options."
    },
    {
        "question": "What are the required input parameters for the AV_IPAdapter node?",
        "answer": "The required input parameters for the AV_IPAdapter node are: ip_adapter_name, clip_name, model, image, weight, and noise."
    },
    {
        "question": "What does the 'weight' parameter control in the AV_IPAdapter node?",
        "answer": "The 'weight' parameter controls the influence of the IP Adapter on the image. It adjusts the strength of the adaptation effect."
    },
    {
        "question": "What are the optional input parameters for the AV_IPAdapter node?",
        "answer": "The optional input parameters for the AV_IPAdapter node are: ip_adapter_opt, clip_vision_opt, attn_mask, start_at, end_at, weight_type, and enabled."
    },
    {
        "question": "What does the 'enabled' parameter do in the AV_IPAdapter node?",
        "answer": "The 'enabled' parameter toggles the application of the IP Adapter and CLIP vision models. When set to false, the adaptation process is skipped."
    },
    {
        "question": "What are the output types of the AV_IPAdapter node?",
        "answer": "The output types of the AV_IPAdapter node are: model, pipeline, and clip_vision."
    },
    {
        "question": "What does the 'pipeline' output represent in the AV_IPAdapter node?",
        "answer": "The 'pipeline' output is a dictionary containing the IP Adapter and CLIP vision models used in the adaptation process. This output provides insight into the model configuration."
    }
]