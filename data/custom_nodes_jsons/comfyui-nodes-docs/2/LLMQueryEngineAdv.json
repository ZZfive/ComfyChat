[
    {
        "question": "What is the purpose of the LLMQueryEngineAdv node in ComfyUI?",
        "answer": "The LLMQueryEngineAdv node in ComfyUI is designed to enhance querying capabilities by utilizing language and embedding models to process and understand complex queries. It integrates advanced settings and post-processing functions to optimize search results based on similarity and relevance."
    },
    {
        "question": "What are the required input types for the LLMQueryEngineAdv node?",
        "answer": "The required input types for the LLMQueryEngineAdv node are llm_model and llm_index. llm_model represents the language and embedding model used for query processing, while llm_index is the index used for information retrieval."
    },
    {
        "question": "What optional input types does the LLMQueryEngineAdv node accept?",
        "answer": "The LLMQueryEngineAdv node accepts the following optional input types: query (user's input query), llm_message (a series of messages for providing additional context), top_k (the number of top results to retrieve), and similarity_cutoff (a threshold for filtering results based on similarity score)."
    },
    {
        "question": "What is the output type of the LLMQueryEngineAdv node?",
        "answer": "The output type of the LLMQueryEngineAdv node is a tuple of strings, representing the processed query results in a structured format."
    },
    {
        "question": "Which infrastructure type is recommended for running the LLMQueryEngineAdv node?",
        "answer": "The recommended infrastructure type for running the LLMQueryEngineAdv node is GPU."
    },
    {
        "question": "What is the default value for the top_k parameter in the LLMQueryEngineAdv node?",
        "answer": "The default value for the top_k parameter in the LLMQueryEngineAdv node is 10."
    }
]