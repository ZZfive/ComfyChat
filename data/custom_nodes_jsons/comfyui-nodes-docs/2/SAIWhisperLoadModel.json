[
    {
        "question": "What is the purpose of the SAIWhisperLoadModel node in ComfyUI?",
        "answer": "The SAIWhisperLoadModel node is designed to load a specified Whisper model into memory, preparing it for speech-to-text operations."
    },
    {
        "question": "Which Whisper model versions are supported by the SAIWhisperLoadModel node?",
        "answer": "The SAIWhisperLoadModel node supports multiple Whisper model versions, including large, base, medium, small, tiny variants, and distil versions for efficient processing."
    },
    {
        "question": "What optional input does the SAIWhisperLoadModel node accept?",
        "answer": "The SAIWhisperLoadModel node accepts an optional 'device' input, which determines the compute device ('cuda' or 'cpu') that will be used for loading the model."
    },
    {
        "question": "What are the output types of the SAIWhisperLoadModel node?",
        "answer": "The output types of the SAIWhisperLoadModel node include the loaded Whisper model, its processor, and the device it is loaded on, ready for speech-to-text processing."
    },
    {
        "question": "What is the infra type recommended for the SAIWhisperLoadModel node?",
        "answer": "The recommended infra type for the SAIWhisperLoadModel node is GPU."
    },
    {
        "question": "What are the Python data types for the 'model' and 'device' inputs in the SAIWhisperLoadModel node?",
        "answer": "In the SAIWhisperLoadModel node, the 'model' input has the Python data type List[str], and the 'device' input also has the Python data type List[str]."
    },
    {
        "question": "What does the SAIWhisperLoadModel node return after loading the Whisper model?",
        "answer": "After loading the Whisper model, the SAIWhisperLoadModel node returns a tuple containing the loaded Whisper model, its processor, and the device it is loaded on."
    }
]