[
    {
        "question": "What is human-parser-comfyui-node?",
        "answer": "human-parser-comfyui-node is an out-of-box human parsing representation extractor that ranks 1st for all human parsing tracks in the third LIP challenge."
    },
    {
        "question": "Which datasets are supported by human-parser-comfyui-node?",
        "answer": "human-parser-comfyui-node supports three popular single person human parsing datasets: LIP, ATR, and Pascal-Person-Part."
    },
    {
        "question": "What are the features of human-parser-comfyui-node?",
        "answer": "The features of human-parser-comfyui-node include an out-of-box human parsing extractor for downstream applications, pretrained models on three popular datasets, training and inference code, and a simple yet effective extension on multi-person and video human parsing tasks."
    },
    {
        "question": "How can I use human-parser-comfyui-node to extract human parsing representations from my own images?",
        "answer": "To extract human parsing representations using human-parser-comfyui-node, put your images in the INPUT_PATH folder, download a pretrained model, and run the provided command with the appropriate dataset and checkpoint path. The output images will be saved in OUTPUT_PATH."
    },
    {
        "question": "What is the purpose of the LIP dataset?",
        "answer": "The LIP dataset is the largest single person human parsing dataset with over 50,000 images. It focuses more on complicated real scenarios and has 20 labels, including various clothing items and body parts."
    },
    {
        "question": "How can I visualize the output images generated by human-parser-comfyui-node?",
        "answer": "To better visualize the output images, human-parser-comfyui-node provides a palette with the output images. It is suggested to read the image using PIL."
    },
    {
        "question": "How can I extend human-parser-comfyui-node for multiple human parsing?",
        "answer": "To extend human-parser-comfyui-node for multiple human parsing, refer to the provided MultipleHumanParsing.md file for more details."
    }
]