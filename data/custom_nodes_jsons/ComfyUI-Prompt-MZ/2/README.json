[
    {
        "question": "What is ComfyUI-Prompt-MZ?",
        "answer": "ComfyUI-Prompt-MZ is a set of nodes based on llama.cpp that are related to prompt words in ComfyUI, including beautifying prompt words and image recognition similar to clip-interrogator."
    },
    {
        "question": "What are some of the recent changes made to ComfyUI-Prompt-MZ?",
        "answer": "Some recent changes include adding the Florence-2-large image interrogation model node, nodes to select local ollama models, the Qianwen 2.0 preset model, optional chat_format and post-processing after image interrogation, and more."
    },
    {
        "question": "How can I install ComfyUI-Prompt-MZ?",
        "answer": "To install ComfyUI-Prompt-MZ, clone the repo into the 'custom_nodes' folder and restart ComfyUI."
    },
    {
        "question": "What are some of the nodes available in ComfyUI-Prompt-MZ?",
        "answer": "Some of the nodes available in ComfyUI-Prompt-MZ include MZ_Florence2CLIPTextEncode, ModelConfigManualSelect (Ollama), CLIPTextEncode (LLamaCPP Universal), ModelConfigManualSelect(LLamaCPP), ModelConfigDownloaderSelect(LLamaCPP), CLIPTextEncode (ImageInterrogator), ModelConfigManualSelect(ImageInterrogator), ModelConfigDownloaderSelect(ImageInterrogator), CLIPTextEncode (OpenAI API), CLIPTextEncode (Phi-3), CLIPTextEncode (LLama3), ImageInterrogator (LLava), ImageCaptionerConfig, LLamaCPPOptions, CustomizeInstruct, BaseLLamaCPPCLIPTextEncode, and BaseLLavaImageInterrogator."
    },
    {
        "question": "What should I do if I encounter the error 'moudle 'llama_cpp' has no attribute 'LLAMA_SPLIT_MODE_LAYER'?",
        "answer": "Upgrade the version of llama_cpp_python to the latest version by downloading and installing it from https://github.com/abetlen/llama-cpp-python/releases."
    },
    {
        "question": "What should I do if I encounter the error 'LLama.dll cannot be loaded (Failed to load shared library LLama.dll)'?",
        "answer": "Switch the CUDA version to 12.1. If you are using the Qiuyue launcher, go to Advanced Settings -> Environment Maintenance -> Install PyTorch -> Select the CUDA 12.1 version in the version selection."
    },
    {
        "question": "What are the credits for ComfyUI-Prompt-MZ?",
        "answer": "The credits for ComfyUI-Prompt-MZ include https://github.com/comfyanonymous/ComfyUI, https://github.com/ggerganov/llama.cpp, and https://github.com/BlenderNeko/ComfyUI_ADV_CLIP_emb."
    }
]