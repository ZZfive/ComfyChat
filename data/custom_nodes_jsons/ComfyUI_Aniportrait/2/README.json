[
    {
        "question": "What is ComfyUI_Aniportrait?",
        "answer": "ComfyUI_Aniportrait is an unofficial implementation of AniPortrait in ComfyUI custom_node, which allows generating animated portraits using Stable Diffusion models."
    },
    {
        "question": "What are the main features of ComfyUI_Aniportrait?",
        "answer": "ComfyUI AniPortrait supports raw video to pose video with reference image, audio-driven animation, and face reenactment."
    },
    {
        "question": "How can users install ComfyUI_Aniportrait?",
        "answer": "Users need to clone the GitHub repository, install the required packages using pip, and download the necessary pre-trained models and weights."
    },
    {
        "question": "What is the purpose of the frame_interpolation implementation in ComfyUI AniPortrait?",
        "answer": "The frame_interpolation implementation is used to speed up the generation process in ComfyUI AniPortrait."
    },
    {
        "question": "Which pre-trained models are required for ComfyUI_Aniportrait?",
        "answer": "The required pre-trained models for ComfyUI_Aniportrait include StableDiffusion V1.5, sd-vae-ft-mse, image_encoder, and wav2vec2-base-960h."
    },
    {
        "question": "What is the recommended video size for the original uploaded mp4 video in ComfyUI_Aniportrait?",
        "answer": "The original uploaded mp4 video should have a square size, such as 512x512, to avoid weird results in ComfyUI_Aniportrait."
    },
    {
        "question": "How can users contact the developer of ComfyUI_Aniportrait?",
        "answer": "Users can contact the developer of ComfyUI_Aniportrait through Twitter (@kurtqian) or Weixin (GalaticKing)."
    }
]