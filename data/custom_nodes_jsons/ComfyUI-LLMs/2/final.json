[
    {
        "messages": [
            {
                "role": "user",
                "content": "What is ComfyUI-LLMs?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI-LLMs is a minimalist node in ComfyUI that allows users to call various language models, including local models, through one API."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "Which visual models does ComfyUI-LLMs support?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI-LLMs supports gemini, glm-4-v, and qwen-v visual models, which can be used to infer cue words."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "How does ComfyUI-LLMs reduce the usage of tokens?"
            },
            {
                "role": "assistant",
                "content": "By default, the seed remains fixed after each generation in ComfyUI-LLMs. Without changing the prompt words, clicking on generate will not trigger a response, thus reducing token usage."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "How can users generate a new response in ComfyUI-LLMs?"
            },
            {
                "role": "assistant",
                "content": "To generate a new response in ComfyUI-LLMs, users need to change the prompt words."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "Where are the settings for ComfyUI-LLMs stored?"
            },
            {
                "role": "assistant",
                "content": "The settings for ComfyUI-LLMs are stored in the 'settings.yaml' file."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "On which projects is ComfyUI-LLMs based?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI-LLMs is based on the secondary development of the following projects: cyberdolphin (https://github.com/whatbirdisthat/cyberdolphin), ComfyUI_GLM4Node (https://github.com/JcandZero/ComfyUI_GLM4Node), and ComfyUI-Qwen-VL-API (https://github.com/ZHO-ZHO-ZHO/ComfyUI-Qwen-VL-API)."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "Under which license is ComfyUI-LLMs distributed?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI-LLMs is distributed under the GPL 3 license."
            }
        ]
    }
]