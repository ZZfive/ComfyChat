[
    {
        "question": "什么是OmniLMM-12B？",
        "answer": "OmniLMM-12B是一个多模态大语言模型，是ComfyUI_MiniCPM-V系列中性能最好的版本。它基于EVA02-5B和Zephyr-7B-β初始化构建，并使用perceiver resampler连接，采用了课程学习的方法在多模态数据上进行训练。"
    },
    {
        "question": "OmniLMM-12B具有哪三个主要特点？",
        "answer": "OmniLMM-12B的三个主要特点是：1. 性能领先，在多个基准测试中取得领先的性能；2. 行为可信，是第一个通过多模态RLHF对齐的综合能力优秀的开源多模态大模型；3. 支持实时多模态交互。"
    },
    {
        "question": "OmniLMM-12B在哪些基准测试中表现出色？",
        "answer": "OmniLMM-12B在MME、MMBench、MMMU、MMHal-Bench、Object HalBench、SeedBench、LLaVA Bench W和MathVista等多个基准测试中表现优异。"
    },
    {
        "question": "OmniLMM-12B是如何实现实时多模态交互的？",
        "answer": "OmniLMM-12B结合GPT-3.5纯文本模型，接受来自摄像头的视频流，并借助工具处理语音输入输出，实现实时多模态交互，无需视频编辑。"
    },
    {
        "question": "如何安装和使用OmniLMM-12B？",
        "answer": "安装步骤包括：1. 克隆仓库并跳转到相应目录；2. 创建conda环境；3. 安装依赖。模型可以从Hugging Face或ModelScope下载。"
    },
    {
        "question": "OmniLMM-12B的参数量是多少？",
        "answer": "OmniLMM-12B的参数量为11.6B。"
    },
    {
        "question": "是否提供OmniLMM-12B的在线演示？",
        "answer": "是的，用户可以通过 http://120.92.209.146:8081 访问OmniLMM-12B的在线演示。"
    }
]