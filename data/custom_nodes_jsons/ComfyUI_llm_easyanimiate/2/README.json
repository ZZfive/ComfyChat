[
    {
        "question": "What does EasyAnimate use to generate captions for frames extracted from videos?",
        "answer": "EasyAnimate uses multi-modal LLMs to generate captions for frames extracted from videos firstly and then employed LLMs to summarize and refine the generated frame captions into the final video caption."
    },
    {
        "question": "What are the additional requirements for video caption using EasyAnimate?",
        "answer": "The additional requirements for video caption using EasyAnimate are thatEasyAnimate uses vLLM and accelerate distributed inference."
    },
    {
        "question": "How can the entire processing of EasyAnimate be made very fast?",
        "answer": "The entire processing of EasyAnimate can be made very fast by utilizing vLLM and accelerate distributed inference."
    },
    {
        "question": "What is the purpose of EasyAnimate's video captioning process?",
        "answer": "The purpose of EasyAnimate's video captioning process is to generate detailed captions for videos."
    },
    {
        "question": "What is the first step in EasyAnimate's video captioning process?",
        "answer": "The first step in EasyAnimate's video captioning process is to extract frames from a video and generate descriptions for them."
    },
    {
        "question": "What is the second step in EasyAnimate's video captioning process?",
        "answer": "The second step in EasyAnimate's video captioning process is to use LLMs to summarize the generated descriptions into a caption."
    },
    {
        "question": "What are the multi-modal LLMs EasyAnimate uses for video captioning?",
        "answer": "The multi-modal LLMs EasyAnimate uses for video captioning are Qwen-VL, ShareGPT4V-7B, deepseek-vl-7b-chat, and llava-v1.6-vicuna-7b."
    }
]