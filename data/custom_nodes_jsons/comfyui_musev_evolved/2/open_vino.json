[
    {
        "question": "What is the purpose of ðŸ¤— Optimum?",
        "answer": "ðŸ¤— Optimum provides Stable Diffusion pipelines compatible with OpenVINO, allowing easy inference on various Intel processors using the OpenVINO Runtime."
    },
    {
        "question": "How can you install ðŸ¤— Optimum?",
        "answer": "You can install ðŸ¤— Optimum by running the command: `pip install optimum[\"openvino\"]`"
    },
    {
        "question": "What needs to be done to load an OpenVINO model and run inference with the OpenVINO Runtime?",
        "answer": "To load an OpenVINO model and run inference with the OpenVINO Runtime, you need to replace `StableDiffusionPipeline` with `OVStableDiffusionPipeline`."
    },
    {
        "question": "How can you load a PyTorch model and convert it to OpenVINO format immediately?",
        "answer": "To load a PyTorch model and convert it to OpenVINO format immediately, you can set `export=True` when using `OVStableDiffusionPipeline.from_pretrained()`."
    },
    {
        "question": "Where can you find more examples and information about exporting and inference of Stable Diffusion models using ðŸ¤— Optimum?",
        "answer": "You can find more examples and information about exporting and inference of Stable Diffusion models using ðŸ¤— Optimum in the Optimum documentation."
    }
]