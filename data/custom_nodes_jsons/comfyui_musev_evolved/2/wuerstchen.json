[
    {
        "question": "What is Würstchen?",
        "answer": "Würstchen is a novel architecture for text-to-image synthesis that combines competitive performance with unprecedented cost-effectiveness for large-scale text-to-image diffusion models."
    },
    {
        "question": "How does Würstchen achieve cost-effectiveness in training and inference?",
        "answer": "Würstchen achieves cost-effectiveness by learning a detailed but extremely compact semantic image representation used to guide the diffusion process, which significantly reduces the computational requirements to achieve state-of-the-art results."
    },
    {
        "question": "What are the three stages in Würstchen architecture?",
        "answer": "The three stages in Würstchen architecture are Stage A (a VQGAN), Stage B (a Diffusion Autoencoder), and Stage C (a model learned in a highly compressed latent space)."
    },
    {
        "question": "Which checkpoint is recommended for general use in Würstchen v2?",
        "answer": "The recommended checkpoint for general use in Würstchen v2 is v2-interpolated, as it has a nice touch of both photorealism and aesthetics."
    },
    {
        "question": "How can inference speed be increased when using Würstchen?",
        "answer": "Inference speed can be increased by using the `torch.compile` function, which can provide a speed-up of about 2-3x."
    },
    {
        "question": "What are some limitations of Würstchen?",
        "answer": "Some limitations of Würstchen include lack of detail in generated images, inability to generate images in resolutions that are not multiples of 128 pixels, inability to render correct text in images, often not achieving photorealism, and difficulty with complex compositional prompts."
    },
    {
        "question": "Where can the original codebase and experimental ideas for Würstchen be found?",
        "answer": "The original codebase and experimental ideas for Würstchen can be found at the GitHub repository dome272/Wuerstchen."
    }
]