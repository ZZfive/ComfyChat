[
    {
        "question": "DreamBooth는 무엇이며 어떻게 작동하나요?",
        "answer": "DreamBooth는 한 주제에 대한 적은 이미지(3~5개)만으로도 stable diffusion과 같이 text-to-image 모델을 개인화할 수 있는 방법입니다. 이를 통해 모델은 다양한 장면, 포즈 및 장면(뷰)에서 피사체에 대해 맥락화(contextualized)된 이미지를 생성할 수 있습니다."
    },
    {
        "question": "DreamBooth를 사용하려면 어떤 dependencies를 설치해야 하나요?",
        "answer": "스크립트를 실행하기 전에 라이브러리의 학습에 필요한 dependencies를 설치해야 합니다. diffusers와 requirements.txt에 있는 패키지를 설치해야 합니다. 추가로 xFormers를 설치하는 것도 좋습니다."
    },
    {
        "question": "DreamBooth 학습 스크립트를 실행하는 명령어는 무엇인가요?",
        "answer": "accelerate launch train_dreambooth.py 명령어를 사용하며, 여러 파라미터를 설정하여 학습을 수행할 수 있습니다. 필요한 파라미터는 --pretrained_model_name_or_path, --instance_data_dir, --output_dir 등이 있습니다."
    },
    {
        "question": "사전 보존(prior-preserving) loss를 사용한 파인튜닝은 무엇인가요?",
        "answer": "사전 보존은 과적합과 language drift를 방지하기 위해 사용되며, 동일한 클래스의 다른 이미지를 학습 프로세스의 일부로 사용합니다. 스크립트에서 --with_prior_preservation 및 --prior_loss_weight 파라미터를 사용하여 설정할 수 있습니다."
    },
    {
        "question": "텍스트 인코더와 UNet을 함께 파인튜닝하기 위한 인수는 무엇인가요?",
        "answer": "텍스트 인코더와 UNet을 함께 파인튜닝하기 위해서는 --train_text_encoder 인수를 전달해야 합니다. 이 기능을 사용하려면 최소 24GB VRAM이 필요합니다."
    },
    {
        "question": "학습 중 체크포인트를 저장하는 방법은 무엇인가요?",
        "answer": "정기적인 체크포인트를 저장하려면 --checkpointing_steps 파라미터에 원하는 스텝 수를 설정하면 됩니다. 저장된 체크포인트에서 훈련을 재개하려면 --resume_from_checkpoint 파라미터를 사용할 수 있습니다."
    },
    {
        "question": "8GB GPU에서 DreamBooth를 학습하려면 어떤 설정을 해야 하나요?",
        "answer": "8GB GPU에서 DreamBooth를 학습하기 위해서는 DeepSpeed를 사용하여 일부 텐서를 VRAM에서 CPU 또는 NVMe로 오프로드해야 합니다. 또한 fp16 혼합 정밀도와 DeepSpeed의 Adam 옵티마이저를 사용해야 합니다. 이 경우 더 많은 시스템 RAM(약 25GB)이 필요합니다."
    }
]