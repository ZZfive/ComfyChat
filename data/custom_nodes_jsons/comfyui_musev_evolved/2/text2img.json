[
    {
        "question": "What is the Stable Diffusion model?",
        "answer": "The Stable Diffusion model is a text-to-image model created by researchers and engineers from CompVis, Stability AI, Runway, and LAION. It is capable of generating photorealistic images given any text input."
    },
    {
        "question": "What is the Stable Diffusion model trained on?",
        "answer": "The Stable Diffusion model is trained on 512x512 images from a subset of the LAION-5B dataset."
    },
    {
        "question": "What text encoder does the Stable Diffusion model use?",
        "answer": "The Stable Diffusion model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts."
    },
    {
        "question": "How many parameters does the Stable Diffusion model have?",
        "answer": "The Stable Diffusion model has 860M UNet parameters and 123M text encoder parameters."
    },
    {
        "question": "What is the research on which Stable Diffusion was built?",
        "answer": "Stable Diffusion was built on top of latent diffusion research, proposed in the paper 'High-Resolution Image Synthesis with Latent Diffusion Models' by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj√∂rn Ommer."
    },
    {
        "question": "What are the benefits of applying diffusion models in the latent space of pretrained autoencoders?",
        "answer": "Applying diffusion models in the latent space of pretrained autoencoders enables DM training on limited computational resources while retaining their quality and flexibility. It allows reaching a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity."
    },
    {
        "question": "How do latent diffusion models achieve state-of-the-art performance on various tasks?",
        "answer": "By introducing cross-attention layers into the model architecture, latent diffusion models are turned into powerful and flexible generators for general conditioning inputs such as text or bounding boxes, enabling high-resolution synthesis in a convolutional manner."
    }
]