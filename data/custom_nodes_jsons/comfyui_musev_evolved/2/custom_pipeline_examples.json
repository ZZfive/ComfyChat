[
    {
        "question": "What is ComfyUI?",
        "answer": "ComfyUI is a GUI that uses a stable diffusion model to generate images and videos."
    },
    {
        "question": "How can I generate question-answer pairs using ComfyUI?",
        "answer": "To generate question-answer pairs using ComfyUI, you need to input the document content. ComfyUI will then construct the question and answer data pairs based on the content and return them in JSON format."
    },
    {
        "question": "What should I do if the community pipeline is not working as expected?",
        "answer": "If the community pipeline is not working as expected, you should open an issue and ping the author for help."
    },
    {
        "question": "How can I load a custom pipeline in ComfyUI?",
        "answer": "To load a custom pipeline in ComfyUI, you need to pass the custom pipeline as the `custom_pipeline` argument to `DiffusionPipeline`. For example: `DiffusionPipeline.from_pretrained('CompVis/stable-diffusion-v1-4', custom_pipeline='filename_in_the_community_folder')`."
    },
    {
        "question": "What is the purpose of the 'one-step-unet' example?",
        "answer": "The 'one-step-unet' example is not useful as a feature but serves as an example of how to add a community pipeline. It is used to demonstrate the process of adding a community pipeline."
    },
    {
        "question": "What is the Stable Diffusion Mega pipeline?",
        "answer": "The Stable Diffusion Mega pipeline allows you to use the main use cases of Stable Diffusion pipelines in a single class. It supports text-to-image, image-to-image, and inpainting in one pipeline."
    },
    {
        "question": "How can I generate images from an audio sample using ComfyUI?",
        "answer": "To generate images from an audio sample using ComfyUI, you can use the 'Speech to Image' pipeline. It uses a pre-trained OpenAI whisper-small and Stable Diffusion to generate images from audio samples."
    }
]