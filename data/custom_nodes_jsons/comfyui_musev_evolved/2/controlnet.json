[
    {
        "question": "What is ControlNet?",
        "answer": "ControlNet is a neural network architecture that adds spatial conditioning controls to large, pretrained text-to-image diffusion models."
    },
    {
        "question": "How does ControlNet control the image generation process?",
        "answer": "ControlNet controls the image generation process by using an additional control image to condition the generation. For example, if a depth map is provided, the ControlNet model generates an image that preserves the spatial information from the depth map."
    },
    {
        "question": "What types of conditional controls can be used with ControlNet?",
        "answer": "Various types of conditional controls can be used with ControlNet, such as edges, depth, segmentation, human pose, etc. These controls can be used with Stable Diffusion, using single or multiple conditions, with or without prompts."
    },
    {
        "question": "Is the training of ControlNets robust with different dataset sizes?",
        "answer": "Yes, the training of ControlNets is robust with both small (<50k) and large (>1m) datasets."
    },
    {
        "question": "Who contributed the ControlNet model to Hugging Face?",
        "answer": "The ControlNet model was contributed to Hugging Face by takuma104."
    },
    {
        "question": "Where can the original codebase for ControlNet be found?",
        "answer": "The original codebase for ControlNet can be found at lllyasviel/ControlNet on GitHub."
    },
    {
        "question": "Where can official ControlNet checkpoints be found?",
        "answer": "Official ControlNet checkpoints can be found on lllyasviel's Hub profile on Hugging Face."
    }
]