[
    {
        "question": "What is Florence-2?",
        "answer": "Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks."
    },
    {
        "question": "What tasks can Florence-2 perform?",
        "answer": "Florence-2 can interpret simple text prompts to perform tasks like captioning, object detection, and segmentation."
    },
    {
        "question": "What dataset does Florence-2 leverage?",
        "answer": "Florence-2 leverages the FLD-5B dataset, which contains 5.4 billion annotations across 126 million images."
    },
    {
        "question": "What is the advantage of Florence-2's sequence-to-sequence architecture?",
        "answer": "Florence-2's sequence-to-sequence architecture enables it to excel in both zero-shot and fine-tuned settings."
    },
    {
        "question": "What is DocVQA?",
        "answer": "DocVQA is a feature that allows users to ask questions about the content of document images, and the model will provide answers based on the visual and textual information in the document."
    },
    {
        "question": "How does DocVQA help with document analysis?",
        "answer": "DocVQA is particularly useful for extracting information from scanned documents, forms, receipts, and other text-heavy images."
    },
    {
        "question": "What is the installation process for DocVQA?",
        "answer": "To use DocVQA, users need to clone the repository to the 'ComfyUI/custom_nodes' folder and install the dependencies in requirements.txt."
    }
]