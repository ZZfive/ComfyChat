[
    {
        "question": "What is ComfyUI-depth-fm?",
        "answer": "ComfyUI-depth-fm is a custom node in ComfyUI that uses the depth-fm monocular depth estimation model to generate depth maps from images."
    },
    {
        "question": "How can I install ComfyUI-depth-fm?",
        "answer": "You can install ComfyUI-depth-fm either by using the ComfyUI-Manager or by cloning the repo to custom_nodes and running 'pip install -r requirements.txt' or 'python_embeded\\python.exe -m pip install -r ComfyUI\\custom_nodes\\ComfyUI-depth-fm\\requirements.txt' if using portable."
    },
    {
        "question": "Where can I find the pruned models for ComfyUI-depth-fm?",
        "answer": "The pruned models for ComfyUI-depth-fm are available in the ComfyUI-Manager or from https://huggingface.co/Kijai/depth-fm-pruned/tree/main. They should be placed in the 'ComfyUI/models/checkpoints' directory."
    },
    {
        "question": "What VAEs are compatible with ComfyUI-depth-fm?",
        "answer": "Any SD1.5/2.1 VAE should work with the ComfyUI-depth-fm node."
    },
    {
        "question": "What is the original model used in ComfyUI-depth-fm?",
        "answer": "The original model used in ComfyUI-depth-fm is from https://ommer-lab.com/files/depthfm/depthfm-v1.ckpt."
    },
    {
        "question": "What is the purpose of DepthFM?",
        "answer": "DepthFM is a state-of-the-art, versatile, and fast monocular depth estimation model that can synthesize realistic depth maps within a single inference step. It also demonstrates capabilities in downstream tasks such as depth inpainting and depth conditional synthesis."
    },
    {
        "question": "How does DepthFM compare to other depth estimators?",
        "answer": "Despite being more efficient, DepthFM outperforms the current state-of-the-art generative depth estimator Marigold zero-shot on a range of benchmark datasets."
    }
]