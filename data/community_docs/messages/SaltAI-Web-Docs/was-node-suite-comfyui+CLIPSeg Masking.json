[
    {
        "question": "What is the purpose of the CLIPSeg Masking node in ComfyUI?",
        "answer": "The CLIPSeg Masking node in ComfyUI is designed to leverage the CLIPSeg model for image segmentation, using both textual and visual inputs to generate a segmentation mask."
    },
    {
        "question": "Which input type is required by the CLIPSeg Masking node?",
        "answer": "The CLIPSeg Masking node requires the 'image' input, which is the input image to be segmented, serving as the visual context for the segmentation process."
    },
    {
        "question": "What is the Python dtype for the 'image' input in the CLIPSeg Masking node?",
        "answer": "The Python dtype for the 'image' input in the CLIPSeg Masking node is 'torch.Tensor'."
    },
    {
        "question": "What optional input does the CLIPSeg Masking node accept to bypass the default model loading process?",
        "answer": "The 'clipseg_model' input is an optional input that, if provided, will bypass the default model loading process in the CLIPSeg Masking node."
    },
    {
        "question": "What are the output types generated by the CLIPSeg Masking node?",
        "answer": "The CLIPSeg Masking node generates 'MASK' and 'MASK_IMAGE' outputs, where 'MASK' is the segmentation mask highlighting areas of interest, and 'MASK_IMAGE' is an inverted version of the segmentation mask represented as an image."
    },
    {
        "question": "What is the Python dtype for the 'MASK_IMAGE' output in the CLIPSeg Masking node?",
        "answer": "The Python dtype for the 'MASK_IMAGE' output in the CLIPSeg Masking node is 'torch.Tensor'."
    },
    {
        "question": "What textual input does the CLIPSeg Masking node utilize to guide the segmentation process?",
        "answer": "The CLIPSeg Masking node utilizes an optional 'text' input, which is a textual description that guides the segmentation process and enables the model to focus on specific elements within the image described by the text."
    }
]