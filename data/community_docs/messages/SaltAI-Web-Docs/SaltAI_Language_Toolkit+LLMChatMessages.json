[
    {
        "question": "What is the LLMChatMessages class in ComfyUI?",
        "answer": "LLMChatMessages is a class under the category SALT/Language Toolkit/Messages in ComfyUI, designed to encapsulate system and user prompts into structured chat messages for further processing or interaction within chat-based applications."
    },
    {
        "question": "What are the input types required by the LLMChatMessages class?",
        "answer": "The LLMChatMessages class requires two input types: 'prompt' of type STRING and 'role' of type COMBO[STRING], which can be either 'SYSTEM' or 'USER'."
    },
    {
        "question": "What type of data does the 'prompt' input accept in the LLMChatMessages class?",
        "answer": "The 'prompt' input in the LLMChatMessages class accepts data of type STRING. It can contain multiline strings and dynamic prompts can be turned off."
    },
    {
        "question": "What does the 'role' input specify in the LLMChatMessages class?",
        "answer": "The 'role' input in the LLMChatMessages class specifies whether the message is from the system or the user, accepting either 'SYSTEM' or 'USER' as a value."
    },
    {
        "question": "What is the output type of the LLMChatMessages class?",
        "answer": "The output type of the LLMChatMessages class is 'LIST', which represents a list of structured chat messages that combine system and user inputs for interaction."
    },
    {
        "question": "In which category can the LLMChatMessages class be found in ComfyUI?",
        "answer": "The LLMChatMessages class can be found under the category 'SALT/Language Toolkit/Messages' in ComfyUI."
    },
    {
        "question": "What function does the LLMChatMessages class use to prepare messages?",
        "answer": "The LLMChatMessages class uses the function 'prepare_messages' to encapsulate the prompts and roles into a list of structured chat messages."
    }
]