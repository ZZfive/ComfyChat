{
    "q1": "What is the purpose of ComfyUI-NSFW-Detection?",
    "a1": "ComfyUI-NSFW-Detection is designed to detect whether images generated by ComfyUI are Not Safe For Work (NSFW).",
    "q2": "How is an image classified as NSFW by ComfyUI-NSFW-Detection?",
    "a2": "It uses a machine learning model to classify images as either safe or not safe for work.",
    "q3": "What action is taken if an image is classified as NSFW?",
    "a3": "An alternative image is returned if the input image is classified as NSFW.",
    "q4": "How is ComfyUI-NSFW-Detection installed?",
    "a4": "To install, clone the repo into the custom_nodes directory of ComfyUI location and then run pip install -r requirements.txt.",
    "q5": "Which file contains the main functionality of ComfyUI-NSFW-Detection?",
    "a5": "The main functionality of the project is encapsulated in the `NSFWDetection` class in the `node.py` file.",
    "q6": "What parameters does the `run` method of the `NSFWDetection` class take?",
    "a6": "The `run` method takes three parameters: `image` (the image to be classified), `score` (the threshold score for classifying an image as NSFW), and `alternative_image` (the image to be returned if the input image is classified as NSFW).",
    "q7": "How can one contribute to the improvement of ComfyUI-NSFW-Detection?",
    "a7": "Contributions are welcome. Users can submit pull requests with any improvements or bug fixes they have.",
    "q8": "Is there any license associated with the usage of ComfyUI-NSFW-Detection?",
    "a8": "Yes, this project is licensed under the terms of the MIT license."
}