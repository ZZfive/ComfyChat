[
    {
        "messages": [
            {
                "role": "user",
                "content": "ComfyUI Ollama是什么，它允许用户做什么？"
            },
            {
                "role": "assistant",
                "content": "ComfyUI Ollama 是一套用于通过 Ollama Python 客户端与 Ollama 交互的自定义节点。它使用户能够将大型语言模型（LLMs）的能力整合到他们的 ComfyUI 工作流程中。"
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "OllamaVision 节点在 ComfyUI Ollama 中的功能是什么？"
            },
            {
                "role": "assistant",
                "content": "OllamaVision节点提供了查询输入图像的能力。用户需要指定一个具有视觉能力的模型，比如'https://ollama.com/library/llava'。"
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "OllamaGenerate 节点在 ComfyUI Ollama 中的功能是什么？"
            },
            {
                "role": "assistant",
                "content": "OllamaGenerate节点允许用户使用给定的提示查询一个大型语言模型（LLM）。这个节点使得用户能够使用选定的大型语言模型进行文本处理。"
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "如何安装 ComfyUI Ollama？"
            },
            {
                "role": "assistant",
                "content": "要安装 ComfyUI Ollama，请按照以下步骤操作：1) 安装 ComfyUI；2) 将仓库克隆到 `custom_nodes` 文件夹中，或者下载为 zip 文件并解压到 `custom_nodes/compfyui-ollama`；3) 重启 ComfyUI。或者，使用 ComfyUI 管理器通过 git URL 安装。"
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "您能提供一个如何在工作流程中一起使用OllamaVision和OllamaGenerate节点的示例吗？"
            },
            {
                "role": "assistant",
                "content": "好的，考虑一个工作流程，在这个工作流程中，你先可视化一个图像，然后使用大型语言模型（LLM）进一步处理它。在OllamaGenerate节点中，将提示设置为输入。你可以在提供的图像中看到一个组合使用示例。"
            }
        ]
    }
]