[
    {
        "messages": [
            {
                "role": "user",
                "content": "What is ComfyUI Ollama and what does it allow users to do?"
            },
            {
                "role": "assistant",
                "content": "ComfyUI Ollama is a set of custom nodes for interacting with Ollama using the ollama Python client. It enables users to incorporate the capabilities of large language models (LLMs) into their ComfyUI workflows."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is the function of the OllamaVision node in ComfyUI Ollama?"
            },
            {
                "role": "assistant",
                "content": "The OllamaVision node provides the ability to query input images. Users need to specify a model with Vision abilities, like 'https://ollama.com/library/llava'."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "What is the function of the OllamaGenerate node in ComfyUI Ollama?"
            },
            {
                "role": "assistant",
                "content": "The OllamaGenerate node allows users to query an LLM with a given prompt. This node enables text processing with a selected LLM."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "How to install ComfyUI Ollama?"
            },
            {
                "role": "assistant",
                "content": "To install ComfyUI Ollama, follow these steps: 1) Install ComfyUI; 2) Clone the repository in the `custom_nodes` folder or download as zip and unzip the contents to `custom_nodes/compfyui-ollama`; 3) Restart ComfyUI. Alternatively, use the ComfyUI Manager to install via a git URL."
            }
        ]
    },
    {
        "messages": [
            {
                "role": "user",
                "content": "Can you provide an example of how to use the OllamaVision and OllamaGenerate nodes together in a workflow?"
            },
            {
                "role": "assistant",
                "content": "Yes, consider a workflow where you visualize an image and then process it further with an LLM. In the OllamaGenerate node, set the prompt as input. You can see a combined usage example in the provided image."
            }
        ]
    }
]