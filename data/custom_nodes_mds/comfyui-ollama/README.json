{
    "data": [
        {
            "subject": "ComfyUI Ollama",
            "question": "What is ComfyUI Ollama and what does it allow users to do?",
            "answer": "ComfyUI Ollama is a set of custom nodes for interacting with Ollama using the ollama Python client. It enables users to incorporate the capabilities of large language models (LLMs) into their ComfyUI workflows."
        },
        {
            "subject": "OllamaVision",
            "question": "What is the function of the OllamaVision node in ComfyUI Ollama?",
            "answer": "The OllamaVision node provides the ability to query input images. Users need to specify a model with Vision abilities, like 'https://ollama.com/library/llava'."
        },
        {
            "subject": "OllamaGenerate",
            "question": "What is the function of the OllamaGenerate node in ComfyUI Ollama?",
            "answer": "The OllamaGenerate node allows users to query an LLM with a given prompt. This node enables text processing with a selected LLM."
        },
        {
            "subject": "Installation",
            "question": "How to install ComfyUI Ollama?",
            "answer": "To install ComfyUI Ollama, follow these steps: 1) Install ComfyUI; 2) Clone the repository in the `custom_nodes` folder or download as zip and unzip the contents to `custom_nodes/compfyui-ollama`; 3) Restart ComfyUI. Alternatively, use the ComfyUI Manager to install via a git URL."
        },
        {
            "subject": "Usage Example",
            "question": "Can you provide an example of how to use the OllamaVision and OllamaGenerate nodes together in a workflow?",
            "answer": "Yes, consider a workflow where you visualize an image and then process it further with an LLM. In the OllamaGenerate node, set the prompt as input. You can see a combined usage example in the provided image."
        }
    ]
}