{
    "data": [
        {
            "question": "What is ComfyUI-AniPortrait and how is it updated?",
            "answer": "ComfyUI-AniPortrait is a GUI that uses the AniPortrait model to generate animated portraits. It is updated with support for the new version of diffusers due to the contribution from WainWong."
        },
        {
            "question": "What is the minimum recommended Python version and CUDA version for building the environment?",
            "answer": "The minimum recommended Python version is >=3.10 and the CUDA version is =11.7."
        },
        {
            "question": "How can I install the required packages for ComfyUI-AniPortrait?",
            "answer": "To install the required packages, run the command `pip install -r requirements.txt`."
        },
        {
            "question": "What are the trained weights included with AniPortrait?",
            "answer": "The trained weights included with AniPortrait are `denoising_unet.pth`, `reference_unet.pth`, `pose_guider.pth`, `motion_module.pth`, and `audio2mesh.pt`."
        },
        {
            "question": "What are the pretrained weights and components required for AniPortrait?",
            "answer": "The pretrained weights and components required for AniPortrait are [StableDiffusion V1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5), [sd-vae-ft-mse](https://huggingface.co/stabilityai/sd-vae-ft-mse), [image_encoder](https://huggingface.co/lambdalabs/sd-image-variations-diffusers/tree/main/image_encoder), and [wav2vec2-base-960h](https://huggingface.co/facebook/wav2vec2-base-960h)."
        },
        {
            "question": "Where can I find the AniPortrait repository?",
            "answer": "The AniPortrait repository can be found at [AniPortrait](https://github.com/Zejun-Yang/AniPortrait)."
        }
    ]
}