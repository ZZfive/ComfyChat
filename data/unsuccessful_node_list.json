[
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/ComfyUI-SVD/README.md": "## Processed Data in JSON Format\n\n```json\n[\n  {\n    \"question\": \"What new feature has Comfy released recently?\",\n    \"answer\": \"Comfy has added official support for SVD (Singular Value Decomposition) functionality.\"\n    \"subject\": \"ComfyUI-SVD\"\n  },\n  {\n    \"question\": \"Where can I find examples of how to use Comfy with SVD?\",\n    \"answer\": \"The documentation provides examples of generating images and videos using Comfy's SVD functionality. You can access them through the provided link.\",\n    \"subject\": \"ComfyUI-SVD\"\n  }\n]\n```"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/eden_comfy_pipelines/README.md": "```json\n{\n    \"questions\": [\n        {\n            \"subject\": \"CLIP_interrogator node\",\n            \"question\": \"What features does the CLIP_interrogator node offer?\"\n            \"answer\": \"The CLIP_interrogator node has options to keep models alive, prepend BLIP captions, save prompts to a text file.\"\n        },\n        {\n            \"subject\": \"CLIP_interrogator node\",\n            \"question\": \"What does the `keep_model_alive` option do?\"\n            \"answer\": \"Keeps CLIP/BLIP models on the GPU after node execution, preventing the need to reload models.\"\n        },\n        {\n            \"subject\": \"VAEDecode_to_folder node\",\n            \"question\": \"What is the purpose of the VAEDecode_to_folder node?\"\n            \"answer\": \"Decodes VAE latents to images and saves them directly to a folder.\"\n        },\n        {\n            \"subject\": \"SaveImage node\",\n            \"question\": \"What features does the SaveImage node offer?\"\n            \"answer\": \"Saves images with an option to add timestamps and save pipeline configurations.\"\n        },\n        {\n            \"subject\": \"eden_comfy_pipelines\",\n            \"question\": \"What is the purpose of the eden_comfy_pipelines collection?\"\n            \"answer\": \"A collection of custom nodes and workflows for ComfyUI.\"\n        },\n        {\n            \"subject\": \"eden_comfy_pipelines\",\n            \"question\": \"What nodes are currently available in the eden_comfy_pipelines collection?\"\n            \"answer\": \"The collection includes the CLIP_interrogator node, VAEDecode_to_folder node, and SaveImage node.\"\n        },\n        {\n            \"subject\": \"eden_comfy_pipelines\",\n            \"question\": \"Are all of the nodes in the eden_comfy_pipelines collection finished?\"\n            \"answer\": \"No, some nodes are still under development.\"\n        }\n    ]\n}\n```"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/comfyui_controlnet_aux/BENCHMARK.md": "\n\n```json\n{\n    \"model_name\": \"ComfyUI_ControlNet_Aux\",\n    \"benchmarks\": [\n        {\n            \"name\": \"EfficientNet-B0 Kün\",\n            \"data\": [\n                {\n                    \"time_per_iter\": 4 Kün_time_per_iter,\n                    \"iters_per_second\": 1 / Kün_time_per_iter\n                }\n            ]\n        },\n        ... Other benchmarks go here\n    ]\n}\n```"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/Plush-for-ComfyUI/README.md": "```json\n{\n    \"version\": \"1.0 viciss/ComfyUI/Plush-for-ComfyUI\",\n    \"description\": \"Plush-for-ComfyUI provides nodes to generate images and videos using AI models.\",\n    \"nodes\": [\n        {\n            \"name\": \"Style Prompt\",\n            \"description\": \"Generates a text prompt based on your selected art style and other criteria.\",\n            \"inputs\": [\n                {\n                    \"name\": \"Prompt\",\n                    \"type\": \"string\"\n                },\n                {\n                    \"name\": \"Image\",\n                    \"type\": \"image\"\n                },\n                {\n                    \"name\": \"Style\",\n                    \"type\": \"string\"\n                },\n                {\n                    \"name\": \"Artist\",\n                    \"type\": \"number\"\n                },\n                {\n                    \"name\": \"prompt_style\",\n                    \"type\": \"string\",\n                    \"default\": \"Tags\"\n                },\n                {\n                    \"name\": \"Max_elements\",\n                    \"type\": \"number\",\n                    \"default\": 10 viciss/ComfyUI/Plush-for-ComfyUI\"\n                },\n                {\n                    \"name\": \"Style_info\",\n                    \"type\": \"boolean\",\n                    \"default\": false\n                }\n            ],\n            \"outputs\": [\n                {\n                    \"name\": \"Prompt\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"name\": \"Advanced Prompt Enhancer\",\n            \"description\": \"Generates text output from your prompt, instruction, image and examples.\",\n            \"inputs\": [\n                {\n                    \"name\": \"Prompt\",\n                    \"type\": \"string\"\n                },\n                {\n                    \"name\": \"Instruction\",\n                    \"type\": \"string\"\n                },\n                {\n                    \"name\": \"Image\",\n                    \"type\": \"image\"\n                },\n                {\n                    \"name\": \"Examples\",\n                    \"type\": \"array\"\n                }\n            ],\n            \"outputs\": [\n                {\n                    \"name\": \"Prompt\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"name\": \"OAI Dall_e 3\",\n            \"description\": \"Generates an image based on your prompt.\",\n            \"inputs\": [\n                {\n                    \"name\": \"Prompt\",\n                    \"type\": \"string\"\n                }\n            ],\n            \"outputs\": [\n                {\n                    \"name\": \"Image\",\n                    \"type\": \"image\"\n                },\n                {\n                    \"name\": \"Dall_e_prompt\",\n                    \"type\": \"string\"\n                }\n            ]\n        },\n        {\n            \"name\": \"Exif Wrangler\",\n            \"description\": \"Extracts Exif and/or AI generation workflow"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/onediff_comfy_nodes/README.md": "**\n```json\n{\n    \"questions\": [\n        {\n            \"subject\": \"ComfyUI Nodes\",\n            \"question\": \"What are the different categories of nodes available in OneDiff ComfyUI nodes?\",\n            \"answer\": \"OneDiff ComfyUI nodes include community nodes such as LoRa and ControlNet, core nodes like Model Acceleration and Quantization, and utility nodes like Image Distinction Scanner.\"\n        },\n        {\n            \"subject\": \"Performance of Community Edition\",\n            \"question\": \"How does OneDiff Community Edition perform compared to the baseline model?\",\n            \"answer\": \"OneDiff Community Edition offers a significant performance improvement of 6 vicissitation over the baseline model.\"\n        },\n        {\n            \"subject\": \"Installation Guide\",\n            \"question\": \"How can I install the onediff_comfy_nodes extension for ComfyUI?\",\n            \"answer\": \"To install the onediff_comfy_nodes extension for ComfyUI, navigate to the onediff directory and run `cp -r onediff_comfy_nodes path/to/ComfyUI/custom_nodes/`.\"\n        },\n        {\n            \"subject\": \"Model Acceleration\",\n            \"question\": \"How can I load checkpoints to accelerate the model in OneDiff ComfyUI?\",\n            \"answer\": \"The \"Load Checkpoint - OneDiff\" node can be used to load checkpoints and achieve model acceleration in OneDiff ComfyUI.\"\n        },\n        {\n            \"subject\": \"Quantization\",\n            \"question\": \"What is the purpose of the \"UNet Loader Int8\" node in OneDiff ComfyUI?\",\n            \"answer\": \"The \"UNet Loader Int8\" node is used to load quantized models, allowing for efficient inference on GPUs.\"\n        },\n        {\n            \"subject\": \"OneDiff Community Examples\",\n            \"question\": \"Give a brief overview of the LoRA example in the OneDiff Community Examples.\",\n            \"answer\": \"The LoRA example showcases the utilization of LoRA models within OneDiff. It allows users to effortlessly change or strengthen these models without recompilation.\"\n        }\n    ]\n}\n```"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/Comfyui_segformer_b2_clothes/README.md": "```json\n{\n  \"questions\": [\n    {\n      \"subject\": \"Comfyui_segformer_b2_clothes\",\n      \"question\": \"What is the purpose of the Comfyui_segformer_b2_clothes model?\"\n      \"answer\": \"The Comfyui_segformer_b2_clothes model is a SegFormer model fine-tuned on the ATR dataset specifically designed for clothes segmentation.\"\n    },\n    {\n      \"subject\": \"Comfyui_segformer_b2_clothes\",\n      \"question\": \"How do I install the Comfyui_segformer_b2_clothes model?\"\n      \"answer\": \"The model can be installed by downloading and placing the custom_nodes directory and renaming the model file to Comfyui_segformer_b2_clothes.\"\n    },\n    {\n      \"subject\": \"Comfyui_segformer_b2_clothes\",\n      \"question\": \"Where can I download the required files for the Comfyui_segformer_b2_clothes model?\"\n      \"answer\": \"The required files can be downloaded from the Hugging Face repository at https://huggingface.co/mattmdjaga/segformer_b2_clothes.\"\n    },\n    {\n      \"subject\": \"Comfyui_segformer_b2_clothes\",\n      \"question\": \"Can the Comfyui_segformer_b2_clothes model be used for human segmentation?\"\n      \"answer\": \"Yes, the model can also be used for human segmentation despite being primarily trained on clothes segmentation.\"\n    },\n    {\n      \"subject\": \"Comfyui_segformer_b2_clothes\",\n      \"question\": \"What are the advantages of using the Comfyui_segformer_b2_clothes model?\"\n      \"answer\": \"The model's fine-tuning on the ATR dataset enhances its accuracy and effectiveness specifically for clothes segmentation.\"\n    }\n  ]\n}\n```"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/ComfyUI-noEmbryo/README.md": "```json\n[\n  {\n    \"question\": \"What are the nodes available in the 'noEmbryo' node set?\",\n    \"answer\": \"The noEmbryo node set includes PromptTermList (1-6 Küntike Prompts), Resolution Scale, and Regex Text Chopper nodes.\"\n  },\n  {\n    \"question\": \"Where can I find the `json` files for each node's Prompt Terms?\",\n    \"answer\": \"The `json` files for each node's Prompt Terms can be found inside the `TermLists` directory inside the node's folder.\"\n  },\n  {\n    \"question\": \"How do I add a new term to a node using the ComfyUI interface?\",\n    \"answer\": \"Connect a text box to the node's `text` input. Write the `label/value` pair in the box using the prescribed format. Enable the `store_input` switch and run a generation job to save the new term.\"\n  },\n  {\n    \"question\": \"What happens if I set either `width` or `height` to 0 purchast 0 Küntike 0 Küntike 0 Küntike 0 Küntike 0 Küntike 0 Küntike 0 Küntike 0 Küntike 0 Küntike 0 Küntike 0 Küntike  gmbh the `Resolution Scale` node has an input image connected?  \",\n    \"answer\": \"If either `width` or `height` is set to 0 viciss at  gmbh the other dimension is used to scale the image. The scaling factor used will be a multiple of 4 viciss.\"\n  },\n  {\n    \"question\": \"How can I find information on the regular expressions supported by the `Regex Text Chopper` node?\",\n    \"answer\": The provided text does not contain information regarding the specific regular expressions supported by the `Regex Text Chopper` node. \n  }\n]\n```\n\n**Note:** The question and answer regarding the last question are intentionally left unanswered as the relevant information on supported regular expressions was not explicitly stated in the given text."
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/ComfyUI-Custom-Scripts/README.md": "```json\n{\n  \"data\": {\n    \"installation\": {\n      \"step1\": \"Clone the repository to your ComfyUI `custom_nodes` directory.\",\n      \"step2\": \"The script will automatically install all custom nodes and scripts.\"\n    },\n    \"features\": [\n      {\n        \"title\": \"Autocomplete\",\n        \"description\": \"Provides embedding and custom word autocomplete. You can quickly default to danbooru tags using the Load button.\"\n      },\n      {\n        \"title\": \"Auto Arrange Graph\",\n        \"description\": \"Adds a menu option to automatically arrange the graph in order of execution.\"\n      },\n      // ... Other features and their descriptions\n    ],\n    \"changelog\": {\n      \"date\": \"20 vicisstifydates\",\n      \"changes\": [\n        {\n          \"date\": \"20 vicisstifydates\",\n          \"description\": \"New feature: ...\",\n          \"details\": \"...\"\n        },\n        // ... Other changes and their details\n      ]\n    }\n  },\n  \"metadata\": {\n    \"title\": \"ComfyUI Custom Scripts\",\n    \"description\": \"Custom scripts and nodes for ComfyUI to enhance your creative workflow.\"\n  }\n}\n```"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/ComfyUI-SVD/README.md": " {\n  \"questions_and_answers\": [\n    {\n      \"subject\": \"ComfyUI-SVD\",\n      \"question\": \"What is the recent update about ComfyUI-SVD?\",\n      \"answer\": \"The article mentions that officially ComfyUI has added support for ComfyUI-SVD, rendering the previous information about manually adding support redundant.\"\n    },\n    {\n      \"subject\": \"ComfyUI-SVD\",\n      \"question\": \"Where can I find the official support documentation for ComfyUI-SVD?\",\n      \"answer\": \"The official support documentation for ComfyUI-SVD can be found on the Comfy Anonymous GitHub page at https://comfyanonymous.github.io/ComfyUI_examples/video/\"\n    },\n    {\n      \"subject\": \"ComfyUI-SVD\",\n      \"question\": \"Is there any information on how to manually add support for ComfyUI-SVD?\",\n      \"answer\": \"This article does not provide any more information about manually adding support for ComfyUI-SVD because ComfyUI has added official support.\"\n    },\n    {\n      \"subject\": \"ComfyUI-SVD\",\n      \"question\": \"Is there any update on ComfyUI-SVD which makes previous information redundant?\",\n      \"answer\": \"Yes, due to the addition of official support by ComfyUI for ComfyUI-SVD, the previous information about manually adding support is no longer necessary.\"\n    }\n  ]\n}"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/comfyui_controlnet_aux/README.md": " Based on the provided documentation, the JSON data for the \"comfyui_controlnet_aux\" subject and the content related to EfficientNets for PyTorch implementation would look something like this:\n\n```json\n[\n    {\n        \"subject\": \"comfyui_controlnet_aux\",\n        \"question\": \"What is the EfficientNets implementation about in PyTorch?\",\n        \"answer\": \"A 'generic' implementation of EfficientNet, MixNet, MobileNetV3, etc. that covers mostly the compute/parameter efficient architectures derived from the MobileNet V1/V2 block sequence, including those found via automated neural architecture search.\"\n    },\n    {\n        \"subject\": \"comfyui_controlnet_aux\",\n        \"question\": \"What is the idea behind the configuration of block layouts in EfficientNets model?\",\n        \"answer\": \"The block layouts of EfficientNets model are configured by a string-based architecture definitions, inspired from the idea of https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_models.py\"\n    },\n    {\n        \"subject\": \"comfyui_controlnet_aux\",\n        \"question\": \"What is the primary goal of EfficientNets for PyTorch compared to other models?\",\n        \"answer\": \"The goal of this models is to minimize computational and parameter usage while achieving high accuracy, which makes them suitable for various applications including on-device machine learning tasks.\"\n    }\n    // Add more questions and answers based on the text content provided, following the format given above.\n]\n```\n\nThis JSON format is suitable for Q&A datasets, as it follows a key-value pair structure with the subject, question, and answer related to the \"comfyui_controlnet_aux\" implementation."
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/onediff_comfy_nodes/README.md": "{\n  \"questions\": [\n    {\n      \"subject\": \"OneDiff ComfyUI Nodes\",\n      \"question\": \"What has been updated for the community edition of OneDiff ComfyUI Nodes, and which device was used for the update on December 7, 2023?\",\n      \"answer\": \"The updated content on DEC 7, 2023, was a performance update for the Community Edition, tested on an RTX 3090 device.\"\n    },\n    {\n      \"subject\": \"OneDiff ComfyUI Nodes\",\n      \"question\": \"Which two workflows saw improvements in the table provided under the Performance of Community Edition section, and what were their respective improvements?\",\n      \"answer\": \"The two workflows that saw improvements were Stable Diffusion (UNet) and LoRA, with a 64.2% and 65.1% increase in performance, respectively.\"\n    },\n    {\n      \"subject\": \"ComfyUI\",\n      \"question\": \"What is the first step in the installation guide for OneDiff ComfyUI Nodes?\",\n      \"answer\": \"The first step in the installation guide is to install and set up ComfyUI.\"\n    },\n    {\n      \"subject\": \"PyTorch and OneFlow\",\n      \"question\": \"How can you install PyTorch and OneFlow according to the installation guide?\",\n      \"answer\": \"To install PyTorch, use the command 'pip install torch torchvision torchaudio'. For OneFlow Community with CUDA 11.x, use the command 'pip install --pre oneflow -f https://oneflow-pro.oss-cn-beijing.aliyuncs.com/branch/community/cu118'. For CUDA 12.x, the command is 'pip install --pre oneflow -f https://oneflow-pro.oss-cn-beijing.aliyuncs.com/branch/community/cu121'.\"\n    },\n    {\n      \"subject\": \"OneDiff\",\n      \"question\": \"How can you install OneDiff?\",\n      \"answer\": \"You can install OneDiff by running the commands 'git clone https://github.com/siliconflow/onediff.git' followed by 'cd onediff && pip install -e .'.\"\n    },\n    {\n      \"subject\": \"OneDiff ComfyUI Nodes\",\n      \"question\": \"What command should you run to install onediff_comfy_nodes for ComfyUI?\",\n      \"answer\": \"You should run 'cd onediff && cp -r onediff_comfy_nodes path/to/ComfyUI/custom_nodes/' to install onediff_comfy_nodes for ComfyUI.\"\n    },\n    {\n      \"subject\": \"OneDiff Enterprise Edition\",\n      \"question\": \"If you need enterprise-level support for your system or business, where can you find more information?\",\n      \"answer\": \"For enterprise-level support, you can refer to the OneDiff Enterprise Edition at 'https://github.com/siliconflow/onediff/blob/main/README.md#onediff-enterprise-edition'.\"\n    },\n    {\n      \"subject\": \"Load Checkpoint - OneDiff\",\n      \"question\": \"What is the optimized feature of the 'Load Checkpoint - OneDiff' node?\",\n      \"answer\": \"The 'Load Checkpoint - OneDiff' node is optimized for OneDiff, allowing users to load checkpoints and accelerate the model.\"\n    },\n    {\n      \"subject\": \"Quantization\",\n      \"question\": \"Which node is required to load quantized models when using Quantization, and what is its relation to the Model Speedup node?\",\n      \"answer\": \"The 'UNet Loader Int8' node is used to load quantized models, and it needs to be used together with the 'Model Speedup' node.\"\n    },\n    {\n      \"subject\": \"Image Distinction Scanner\",\n      \"question\": \"What is the purpose of the 'Image Distinction Scanner' node, and how is the output visualized?\",\n      \"answer\": \"The 'Image Distinction Scanner' node is used to compare differences between two images and visualize the resulting variances.\"\n    },\n    {\n      \"subject\": \"LoRA\",\n      \"question\": \"What is the purpose of the LoRA community example in the OneDiff ComfyUI Nodes documentation?\",\n      \"answer\": \"The LoRA example demonstrates how to use Loras effectively, allowing the change of LoRA models or adjustment of their strength without needing to recompile.\"\n    },\n    {\n      \"subject\": \"ControlNet\",\n      \"question\": \"What is demonstrated in the ControlNet example found in the OneDiff ComfyUI Nodes documentation, and which types does it support?\",\n      \"answer\": \"The ControlNet example shows openpose controlnet speedup, and it supports a wide range of controlnet types, including depth mapping, canny,"
    },
    {
        "/root/code/ComfyChat/data/custom_nodes_mds/ComfyUI-Crystools-save/feature_request.md": "{\n  \"questions\": [\n    {\n      \"question\": \"What is the purpose of the provided document?\",\n      \"answer\": \"The purpose of the provided document is to serve as a template for submitting a feature request for the ComfyUI-Crystools-save project.\"\n    },\n    {\n      \"question\": \"What is the first section in the document for?\",\n      \"answer\": \"The first section is for providing a name, about description, title, labels, and assignees related to the feature request.\"\n    },\n    {\n      \"question\": \"What should be described in the 'Is your feature request related to a problem? Please describe.' section?\",\n      \"answer\": \"This section requires a clear and concise description of the problem that the feature request aims to address.\"\n    },\n    {\n      \"question\": \"What needs to be included in the 'Describe the solution you'd like' section?\",\n      \"answer\": \"This section requires a clear and concise description of the desired solution or the outcome that the submitter wants to achieve through the feature request for the ComfyUI-Crystools-save extension.\"\n    },\n    {\n      \"question\": \"What is the purpose of the 'Describe alternatives you've considered' section?\",\n      \"answer\": \"The purpose of this section is to provide a description of any alternative solutions or features that the submitter has considered while formulating the feature request for the ComfyUI-Crystools-save extension.\"\n    },\n    {\n      \"question\": \"What can be added in the 'Additional context' section?\",\n      \"answer\": \"The 'Additional context' section can include any other relevant information, context, or screenshots that might help in understanding and evaluating the feature request for the ComfyUI-Crystools-save extension.\"\n    },\n    {\n      \"question\": \"Is the subject of the proposed question and answer data related to a specific custom node or plugin?\",\n      \"answer\": \"Yes, the subject is related to a specific custom node or plugin, which is the ComfyUI-Crystools-save extension.\"\n    }\n  ]\n}"
    }
]