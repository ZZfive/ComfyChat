AI視頻創作的熱潮是從圖商視頻開始的輸入一張靜態的圖片AI就能讓它動起來生成最長可達十幾秒的一段動態視頻光影自然細緻細節栩栩如生運動也十分流暢堪比某些不費視頻素材網站上出售的高質量空鏡內容還可以填滿行空不管是現實存在的還是不存在的一下子把做了多年特效的UP主我給趕沉默了
這種幾乎可以重塑剪輯後期產業的進展讓大眾將關注集中在了一系列圖生視頻的AI工具上例如最早出圈的Runway Gen2華人學霸打造的Picard等等這強大的工具很受歡迎唯一的缺點可能就是要花錢還挺貴一個月大幾百的訂閱費用你下得去手嗎但就在去年年底StableDiffusion的開發公司開源模型界的扛旗手Stability AI發布了他們的視頻模型Stable Video Diffusion簡稱SVD成功依靠其免費可本地運行的特性與不輸主流產品的質量在AI視頻領域佔據了一席之地
和剛剛介紹的一樣它可以幫助你從一張靜態圖片乃至一段提示詞就去生成一系列絲滑、流暢且富有風格特色的視頻分鏡你可以用它做動畫、做視頻素材甚至是會有劇情的連貫短片連央視的宣傳片裡都有它的身影出現你想知道它要怎麼用嗎在今天這期視頻裡我們就來
來聊聊它的安裝方法和運用精髓以及藉助各種工具實現視頻的運動設計智能構想以及補身放大等功能的方式看完這期視頻無需在付費應用裡購買價值幾百的會員在自己的電腦上你也可以輕鬆零成本的體驗AI商場視頻的樂趣教程內容比較充實我猜你肯定不只要看一遍建議先點個收藏再開始接下來的學習準備好了嗎我們開始直接課的SVD探索之旅吧
按照惯例 从它的下载与安装开始讲起吧你可以在StabilityAI官方的HoneyBase模型页面下载到最新版本的SVD模型最早发布的有两个版本它们的区别是用于训练的视频帧数不带XT的原版是在14帧视频上训练的而加了XT的版本有额外在25帧的视频上进行过微调理论上运动会更加流畅自然我会推荐你下载这个最新的1.1版本XT模型以后也完全有可能有更新版本的模型释出有限用最新版
下載了模型以後要去哪裡使用它呢?絕大多數SVD的玩家會使用Config UI中的工作流來運行模型目前,最新版本的Config UI已經原生支持了SVD的相關功能界點如果你有Config UI的操作經驗可以直接將SVD模型放置進Config UI的Checkpoint文件檔內和其他的繪圖模型一起就可以使用它了
如果你之前完全没有接触过config UI也完全不用担心我在这期视频下面将完整的config UI程序与SVD模型打了个包并附上了这期视频里会运用到的所有工作流你可以给这个视频一键三连然后在这几个按钮下面的简介区里找到他们的下载方式下载并解压后双击这个run NVIDIA GPU并按照后面讲解的方式去运用它你也可以轻松在自己的电脑上使用这个模型
另外一個可以用上SVD的方式則是最近新進流行起來的Forge UI這個出自ControlNet作者之首的WebUI改良版將SVD功能作為一個內置擴展植入了進去對習慣WebUI的用戶來說操作或許會更加友好使用這些方式在本地運行SVD模型時對GPU的性能是有一定要求的
根据实际测试绘制14帧视频的显存需求大约在12GB左右绘制25帧会更高低于这个水平的设备可以运行但有爆显存降速的风险在生产视频的过程中我们会用到的其他工具也可能会产生额外的显存占用因此如果你有一块显存在16G以上的GPU就可以本地无压力唱完SVD一类的视频生产模型了例如支持了本期教程制作的微星显卡最新上市的GeForce RTX Gaming X Slim魔龙系列的4070Ti Super就拥有16G的超大显存与接近4080的核心性能与绘图
保證了SVD這種本地部署的視頻模型的生成體驗根據史冊以它的性能機種繪製一個標準的1024x576分辨率14幀的視頻只需要大約40秒的時間你可以以它作為標準衡量你使用SVD生成視頻的速度當然並不是說低於這個配置線就和SVD無緣了你還可以通過它的官方在線應用這個Stable Video網站來運行它但它不是本地運行的免費的額度用完以後也需要付費購買credits我們今天並不會著重介紹但要是你看了接下來的內容感興趣也可以拿它去嘗試一下
那接下來我們就從最基礎的圖生視頻功能開始了解如何在一分鐘之內實現一個畫鏡為動的操作在KofiUI裡加載這個圖生視頻的SVD工作流它的結構非常簡單和最基本的文聲圖有諸多相似之處首先我們在最左側的Checkpoint加載器這裡加載剛剛下載下來的SVD模型隨後在下方的圖片加載器處輸入一張想要讓它動起來的初始圖片可以直接從電腦上的文件夾把圖片拖拽進來
這張初始圖片的尺寸最好和你最後生產的視頻尺寸比例保持一致那視頻的尺寸在哪裡調整呢?看到右邊這個條件接點在這裡你可以設置視頻的寬度、高度和幀數、幀率等基本選項其中視頻尺寸我會推薦按照默認設置的1024x576來
因为SVD模型是在这个尺寸的视频上训练的所以我们也应该尽可能把初始图像拆解到16比9的比例上视频的帧数决定了视频的总长度同样会根据你选用的SVD模型而已原版的最佳选择是14帧XT版则是25帧而FPS代表每秒播放的帧数可以维持默认6不变这样会生成一个约4秒左右的视频
隨後再在右邊設置可以採樣器裡的刻像參數這些參數和繪圖時的作用基本一致如果你不了解它們的詳細作用也可以維持默認不變甚至完畢點擊下邊欄上的添加提示詞對列等待讀條完畢在最右邊的保存窗口裡就會輸出一段視頻你的圖片就動起來了你可以在config UI跟目錄的輸出文件夾裡找到這些圖片也可以右鍵點擊將它保存下來很簡單對吧
不过按照默认的这一套参数运行有时生成的视频效果会有点奇怪碰到类似这样的问题时我们就得去更改下面这一系列和视频生成有关的参数了这其中有三个是你需要众里关注的首先是这个运动桶ID它是SVD模型里最直观的控制视频运动幅度的参数默认127 范围从1到255越大运动幅度就越剧烈如果运动太过剧烈导致画面变形了就降低它反过来如果画面不怎么动就可以适当增大它
和運動間接相關的另一個參數是這兩個階段裡的最小CFG和KSampler裡的CFG數值CFG是五分類似指導的縮寫和圖像繪製中一樣它控制繪製內容與條件的相關性你會看到有兩個數值是因為SVD採用了隨幀數動態控制CFG的思路在繪製第一幀內容的時候應用最小值然後逐漸增大到最後一幀時變成KSampler裡的最終CFG以此來適應視頻不斷變化的畫面
官方解釋它的作用是保持原始圖像的忠實程度低了畫面會更自由而高了畫面就會更穩定我在實際摸索中發現它不會影響大的運動構成但會影響運動推導的細節如果你的畫面裡出現了類似這樣糊成一團的成分就可以適當增大另外Safety太高或太低也會導致畫面的異常
如果碰上這種情況就應當把它拉回到正常的區間內還有一個有用的三速是這個增強水平直接理解就是添加到圖片中的造成量它越高視頻與初始真的差異就越大所以也可以通過增加它來獲得更多運動但它的數值的調整很敏感一般不超過1不同場合使用的水平不同多數時候你可以讓它保持默認但當你在使用與默認尺寸不同的視頻尺寸時最好把它增大到0.2到0.3否則畫面就有很大概率會是錯亂的
了解了這些你就可以盡情享受SVD的便利了有一張圖片就能做出一段生動的視頻素材來不過這離我們幻想的用嘴拍視頻好像還有一段距離畢竟還得有圖片對吧但其實文生視頻和圖稱視頻本就只有一線之隔而文生圖的技術在過去一年多的錘鏈裡早就已經高度成熟了因此我們可以用一套非常流暢的文生圖稱視頻的絲滑鏈招實現從文
自導視頻的生成控制在config.io案中加載這個工作流比起剛剛的圖稱視頻它只是在前面多了一個文聲圖的節點組合在最左邊的模型加載器這裡選擇一個合適的繪圖大模型無論是SD1.5還是Excel的都可以然後在上方的文本編碼器窗口裡用英文輸入一段畫面的描述按照剛剛提到的方法再把視頻相關的三數設置好點擊生成它就會在第一個節點組裡
完成生成圖片的工作 隨後立刻將圖片轉化為一個動態視頻看 是不是也非常流暢 輕鬆其實 SVD 用起來是非常自由的原則上只要你能給它為一張圖片 它都能幫助你讓圖片動起來因為 AI 視頻模型的訓練 就是向 AI 大量投為視頻片段讓它學習這些視頻在不同時間節點上的靜態針的差異久而久之 視頻的所有動態 在它的眼裡就會變得有跡可循
這個時候向AI輸入一張靜態的圖片它就會有能力去預測接下來一段時間內它會發生的畫面運動也因此決定這個視頻成色最重要的參數其實就是這張圖片如果你收看過之前我的頻道裡更新的關於Stable Division的應用教程你還可以利用多種手法繪製符合需要的圖片從而實現有指向性的視頻創作正好微星近期在各大平台舉辦了一個AI繪圖創作比賽
希望大家可以通過StableDivision圍繞龍與微星顯卡的主題創作一副AI商城作品作為全球電競產業的僑出品牌微星的顯卡產品也是眾多AIGC愛好者們有力的創作工具近期發布的GeForce RTX 40 Super系列顯卡就為AI繪圖創作注入了強大的動力微星朝辦這次比賽非常用心目光體現在他們準備的獎品上就是三塊開頭我們介紹過的具有16G大顯存的4070Ti Super魔龍顯卡
為了幫助大家更方便、快捷地創造出符合要求的作品他們還特地聘請了專門的模型訓練師把微星全系列顯卡的形象列成了Lora只需要簡單地在生成中加入Lora再敲幾個提示詞就可以把一塊生動的微星顯卡植入到作品中啦對了,和以往一些AI會讀賽事不同他們這次的徵集範圍不僅包括了圖像作品還有視頻
有了這樣一張靜態的圖片作品以後我其實非常推薦你將它導入到SVD裡跑一跑因為它有些時候可以給你製造不少驚喜在繪製的過程裡你還可以使用ContraNet、IP Adapter等工具輔助進行風格化的延伸從而創作出更富有特色的作品這不是今天的重點但如果你想學習該怎麼做不妨看看我們之前更新的一些視頻
而在這種強風格屬性的作品裡SVD同樣可以給你驚喜看那SVD跑一跑一個水墨流轉山水變換的效果也就做出來了然而使用SVD出圖的一大難點在於它的動態內容某種程度上是不可控的你想讓它動哪裡動什麼其實現階段還是比較難去控制的所以要獲得一個令人滿意的結果我們總是需要反覆抽卡
然後反覆翻車不過得益於config UI裡各種功能強大的自定義接連我們可以用一些較為有效的手段控制生成動態內容的區域從而提高視頻的可塑性這樣你用它生成的視頻就會更加聽話了首先是盲版在繪製靜態圖片的時候我們可以靠盲版重繪精確控制AI紙重回畫面裡的其中一小部分而在生成視頻時我們也可以用類似的手段讓一個視頻裡只有一小部分動起來RUNWAY之前有一個大熱的運動筆刷功能就可以做到這樣的效果
我在 Confi UI 裡用一系列的節點為你復刻了一下加載這個動態筆刷的工作流同樣在最左邊這裡導入出示圖片右鍵點擊一下圖像選擇在遮罩編輯器中打開在打開的介面裡用筆刷塗抹你想要畫面運動的部分左下角有選項可以調節筆觸大小畫寸了
可以按清楚按鈕重來畫完以後,點擊右下角的Save to Note然後再像剛剛一樣設定好視頻參數,運行即可看,我們就通過這樣的方式嚴格限定了這個視頻的動態範圍了這個工作流裡還設計了一些輔助性質的選項這裡有兩個開關分別控制萌版的反轉和邊緣的語化反轉會把萌版控制的繪製區域倒轉過來默認是被關閉的但如果你將它啟用了那你所圖畫的區域就會變成固定不變的區域
而邊緣語化默認是開啟的目的是為了讓這些區域和動態區域的過渡變得更加自然如果你看到了生硬的接縫邊緣可以在這裡再增大一點數值這種哪裡要動畫哪裡的感覺還挺舒適的但在一些更複雜的情形裡靠手塗門板控塗的精確度還是太低了這個時候我們就可以求助一些非常厲害的智能抠圖工具來實現更精確的運動控制
这里有另一个工作流,运用到了Configure中的Segment Anything组件通过两个功能强大的AI抠图模型可以帮助我们智能识别并选定图像中的区域其中Grounded Dino是一个强大的零样门检测器能够根据文本描述来检测图像中的任意物体生成一个大致的区域范围而Sam可以在这个区域里做更仔细的分割把这个东西抠出来并生成相应的蒙版
在 WebUI 裡有一個非常受歡迎的擴展segment-anything 就用到了這項技術而 convi 中也有類似的功能界點用它們在靜態圖片上智能扣圖早就輕而易舉把它們架接到 SPD 的工作流裡會有什麼奇妙的化學反應呢?這個工作流的使用方式和剛剛那個差不多但不需要手塗門板了
只需要在這裡用提示詞描述你想要動起來的畫面元素再按照剛剛講的方式設置好視頻參數看它就會智能地識別出畫面裡的對應位置並且使用和剛剛類似的手段生成門板讓它動起來了這樣選取區域精確度和效率都比手畫高多了但我做了不少測試在口取區域太小的情況下是不會有動態效果的而在我們限時生成區域的情況下不少動態內容也有可能會出框造成比較違和的觀感這種情況我建議你降低幾個控制動態選評的參數再來試試看
嚴格來說,SVD生成的視頻質量其實並不能算非常高比如它默認生成的幀率只有6但常規的互聯網視頻幀率一般是24-30幀而它的理想生成尺寸是1024x576x1.875倍才是我們常見的1080P清晰度但這些都不是問題
因为我们已经有很多成熟的视频超分放大与补帧差值手段来升级视频的清晰度和流畅度在config UI里就可以实现再提供一个工作流你可以在前面导入svd生成的成品视频然后在这里设置放大宽度、帧数等信息就可以调用resrgm模型进行放大以及fil模型做补帧这里我也设计了一个小开关如果你只想单独补帧或者放大都可以用它来控制
除此之外,我们在上一集视频里介绍过的这个Film扩展里面也内置有放大和补帧功能,用它来操作也是相当简单的如果你有预算,还可以使用一些更成熟的商业软件比如Topaz Video,来实现类似的效果另外,如果你使用Config UI自带的SVD工作流生成视频默认的保存格式是WebPay图片可能不是很兼容一些视频编辑应用这个时候,我会建议你安装这个Video Hypersilver的节点套件使用它里面的这个Video Combine节点替换默认的WebPay保存节点就可以在下面把输出格式设置为MP4等更常见的视频格式啦
總的來說,SVD是目前開源領域最具競爭力的視頻模型它的操作十分簡單,能和已有的AI繪圖流程無縫接軌應用場景可能也遠比你想像的更加豐富在很多傳統渠道的媒介裡一些純靜態的展示場景就可以通過SVD非常輕鬆的轉換為動態的演示無需進行複雜的建模、後期
它對內容創作也是有革命性意義的我在網上看到了很多借助SVD生成的動態視覺乃至短片作品真的非常驚艷不過嘛它的短板和缺點也是很明顯的或者說現階段幾乎所有視頻生成模型的短板就是可控性差有如SD發展早期我們只能靠不斷調整魔咒和種子來獲取更好的結果
現階段想獲得一個符合預期的SVD視頻也只能靠不斷微調這些參數來玩抽卡遊戲但好在這個卡抽的還挺快的平均每半分鐘到一分鐘就可以生成一個視頻生成同等長度視頻的時間比起Animative等項目都要快而隨著技術的發展它只會變得越來越快相應偉大官方開發的Tensor2T加速庫目前就已經支持了SVD的生成加速用經過它編譯的模型生成視頻還能再快上40%這套技術方案目前已經相當成熟我們之前也做過一期專題內容
发现它对AI绘画方面的加速效果非常显著最快可以让显卡的性能提升三倍以上借助Strain Diffusion等技术还能实现每秒百帧以上的实时转会如果你想了解更多可以通过屏幕上的链接收看之前的视频比起那会儿现在的Tensor RT已经完整支持了包括Lora、ContraNet、Animative等常见应用而且在市面上所有常见的SD操作界面里都是通用的此外,我摸索SVD的过程中也稍微把握了那么一点点抽出好卡的秘诀
當我們的畫面裡有比較突出的人物主體比較顯著的動態元素乃至比較有空間層次感的場景時它產出自然流暢的運動的概率就會高很多而SVD生成一些近物遠景的時候出好卡的概率更高但要他去畫一些細緻的動作就很容易出現像這樣非常不真實不自然的結果說白了和早期AI繪圖畫不好手腳是一樣的
不過,這些模型肯定會不斷迭代進步在清晰度、關聯性上做得更好將來如果有 ContraNet 級別的視頻控制網絡出現我們剛剛提到的這些問題一定都會迎刃而解在說未來可期的同時它依然提供了視頻創作的一種嶄新可能性讓每個人都有機會成為自己的大篇導演更低成本卻更加豐富的視頻素材
也會為現在的內容產業注入更多新鮮血液