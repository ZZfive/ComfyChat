

RAG_PROMPT_TEMPLATE = dict(
    ZH_PROMPT_TEMPALTE="""使用提供的上下文来回答用户问题。如果你不知道答案，就说你不知道。总是使用中文回答。
        问题: {question}
        可参考的上下文：
        ···
        {context}
        ···
        如果基于给定的上下文无法做出回答，请回答：当前数据库中没有相关内容，你不知道。
        有用的回答:""",
    
    EN_PROMPT_TEMPALTE="""Use the context provided to answer user questions. If you don't know the answer, say you don’t know. Always answer in English.
        Question: {question}
        Reference context:
        ···
        {context}
        ···
        If no answer is possible based on the given context, please answer: There is no relevant content in the current database, you don't know.
        Useful answers:""",)


PROMPT_TEMPLATE = dict(
    ZH_PROMPT_TEMPALTE="""你是一个人工智能助手，可以回答用户输入的问题；注意不要生成涉及政治、辱骂、色情、恐暴、宗教、网络暴力、种族歧视等违禁内容。
        问题: {question}
        如果不知道用户输入问题，直接回答“不知道”。
        回答:""",
    
    EN_PROMPT_TEMPALTE="""You are an AI assistant that can answer questions entered by users; be careful not to generate prohibited content involving politics, insults, pornography, terrorism, religion, cyber violence, racial discrimination, etc.
        Question: {question}
        If you don't know the user input question, just answer "I don't know".
        Answers:""",)


ANSWER_NO_RAG_TEMPLATE = dict(
    ZH_PROMPT_TEMPALTE="""{answer}（RAG判断当前数据库不包含相关信息，此回答由LLM直接生成）""",
    
    EN_PROMPT_TEMPALTE="""{answer} (RAG determines that the current database does not contain relevant information. This answer is generated directly by LLM)""",)

ANSWER_RAG_TEMPLATE = dict(
    ZH_PROMPT_TEMPALTE="""{answer}（此回答由RAG生成）""",
    
    EN_PROMPT_TEMPALTE="""{answer} (this answer was generated by RAG)""",)

ANSWER_LLM_TEMPLATE = dict(
    ZH_PROMPT_TEMPALTE="""{answer}（此回答由LLM直接生成）""",
    
    EN_PROMPT_TEMPALTE="""{answer} (this answer was generated directly by LLM)""",)

ANSWER_SUFFIXES = ["（RAG判断当前数据库不包含相关信息，此回答由LLM直接生成）",
                   "(RAG determines that the current database does not contain relevant information. This answer is generated directly by LLM)",
                   "（此回答由RAG生成）", "(this answer was generated by RAG)",
                   "（此回答由LLM直接生成）", "(this answer was generated directly by LLM)"]